# 基本設計書：LangGraph搭載 自律型リサーチエージェント

## 1. システムアーキテクチャ概要

### 1.1 全体構成

本システムは、LangGraphのステートフルなグラフ構造を活用し、4つのエージェントノード（Supervisor、Researcher、Writer、Reviewer）が循環的に協調動作することで、高品質なリサーチレポートを自律的に生成する。

### 1.2 技術スタック

- **フレームワーク**: LangGraph (LangChain 1.0以上)
- **LLM**: OpenAI GPT-4o (Function Calling対応)
- **検索API**: Tavily Search API
- **ステート管理**: LangGraph StateGraph + TypedDict
- **永続化**: LangGraph Checkpointer (MemorySaver / Redis)
- **言語**: Python 3.10以上
- **依存管理**: Poetry / pip

### 1.3 アーキテクチャ図

```
┌─────────────────────────────────────────────────────────────┐
│                    User Input Layer                          │
│              (テーマ入力、承認入力)                            │
└────────────────────┬────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│              LangGraph StateGraph                            │
│  ┌──────────────────────────────────────────────────────┐   │
│  │              Shared State (TypedDict)                │   │
│  │  - messages: List[BaseMessage]                      │   │
│  │  - task_plan: ResearchPlan                          │   │
│  │  - research_data: List[SearchResult]                │   │
│  │  - current_draft: str                                │   │
│  │  - feedback: Optional[str]                           │   │
│  │  - iteration_count: int                              │   │
│  │  - next_action: Literal["research", "write", "end"]  │   │
│  └──────────────────────────────────────────────────────┘   │
│                                                               │
│  ┌──────────────┐                                            │
│  │  Supervisor  │◄──────────────────────────────────────┐   │
│  │  (Planning & │                                         │   │
│  │   Routing)   │                                         │   │
│  └──────┬───────┘                                         │   │
│         │                                                  │   │
│         ├──────────────┐                                  │   │
│         │              │                                  │   │
│         ▼              ▼                                  │   │
│  ┌──────────────┐  ┌──────────────┐                      │   │
│  │  Researcher  │  │    Writer    │                      │   │
│  │  (Web Search)│  │  (Drafting)  │                      │   │
│  └──────┬───────┘  └──────┬───────┘                      │   │
│         │                 │                               │   │
│         └────────┬────────┘                               │   │
│                  │                                        │   │
│                  ▼                                        │   │
│         ┌──────────────┐                                  │   │
│         │   Reviewer   │                                  │   │
│         │  (Critique)   │                                  │   │
│         └──────┬───────┘                                  │   │
│                │                                          │   │
│                └──────────────────────────────────────────┘   │
│                                                               │
│  ┌──────────────────────────────────────────────────────┐   │
│  │              External Tools                            │   │
│  │  - TavilySearchTool                                   │   │
│  │  - WebScraperTool                                     │   │
│  └──────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────┘
                     │
                     ▼
┌─────────────────────────────────────────────────────────────┐
│              Output Layer                                    │
│         (Markdown Report, Sources JSON)                      │
└─────────────────────────────────────────────────────────────┘
```

## 2. ディレクトリ構造

```
deep_research_agent_langgraph/
├── README.md
├── requirements.txt
├── pyproject.toml
│
├── src/
│   ├── __init__.py
│   │
│   ├── graph/
│   │   ├── __init__.py
│   │   ├── graph_builder.py          # グラフ構築メイン
│   │   ├── state.py                  # ステートスキーマ定義
│   │   └── edges.py                  # エッジ/ルーティングロジック
│   │
│   ├── nodes/
│   │   ├── __init__.py
│   │   ├── supervisor.py             # Supervisorノード実装
│   │   ├── researcher.py             # Researcherノード実装
│   │   ├── writer.py                 # Writerノード実装
│   │   └── reviewer.py               # Reviewerノード実装
│   │
│   ├── tools/
│   │   ├── __init__.py
│   │   ├── search_tool.py            # Tavily検索ツール
│   │   └── scraper_tool.py           # Webスクレイピングツール
│   │
│   ├── schemas/
│   │   ├── __init__.py
│   │   ├── state_models.py           # ステート用データモデル
│   │   └── data_models.py            # 共通データモデル
│   │
│   ├── prompts/
│   │   ├── __init__.py
│   │   ├── supervisor_prompt.py     # Supervisor用プロンプト
│   │   ├── researcher_prompt.py     # Researcher用プロンプト
│   │   ├── writer_prompt.py          # Writer用プロンプト
│   │   └── reviewer_prompt.py        # Reviewer用プロンプト
│   │
│   ├── utils/
│   │   ├── __init__.py
│   │   ├── checkpointer.py           # チェックポイント設定
│   │   ├── logger.py                 # ロギング設定
│   │   └── validators.py             # バリデーション関数
│   │
│   └── config/
│       ├── __init__.py
│       └── settings.py               # 設定管理（環境変数等）
│
├── tests/
│   ├── __init__.py
│   ├── test_nodes.py
│   ├── test_graph.py
│   └── test_tools.py
│
└── examples/
    └── example_usage.py              # 使用例
```

## 3. ステートスキーマ設計

### 3.1 State定義（TypedDict）

LangGraphの`TypedDict`を使用して、型安全なステートを定義する。

```python
from typing import TypedDict, List, Optional, Literal, Annotated
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages

class ResearchState(TypedDict):
    """リサーチエージェントの共有ステート"""
    
    # メッセージ履歴（LangGraph標準）
    messages: Annotated[List[BaseMessage], add_messages]
    
    # 調査計画
    task_plan: Optional[ResearchPlan]
    
    # 収集された研究データ
    research_data: List[SearchResult]
    
    # 現在のドラフト
    current_draft: Optional[str]
    
    # Reviewerからのフィードバック
    feedback: Optional[str]
    
    # ループ回数（無限ループ防止）
    iteration_count: int
    
    # 次のアクション（ルーティング用）
    next_action: Literal["research", "write", "review", "end"]
    
    # 人間介入フラグ
    human_input_required: bool
    human_input: Optional[str]
```

### 3.2 データモデル（Pydantic）

```python
# schemas/data_models.py

from pydantic import BaseModel, Field
from datetime import datetime
from typing import List, Optional, Dict

class ResearchPlan(BaseModel):
    """調査計画モデル"""
    theme: str
    investigation_points: List[str] = Field(default_factory=list)
    search_queries: List[str] = Field(default_factory=list)
    plan_text: str
    created_at: datetime = Field(default_factory=datetime.now)

class SearchResult(BaseModel):
    """検索結果モデル"""
    title: str
    summary: str
    url: str
    source: str = "tavily"
    published_date: Optional[str] = None
    relevance_score: Optional[float] = None
```

## 4. ノード設計詳細

### 4.1 Supervisorノード

**役割**: 計画立案、ルーティング決定、終了判定

**入力**: `ResearchState`

**出力**: `ResearchState` (next_actionを更新)

**処理フロー**:
1. メッセージ履歴から現在のタスクを把握
2. `task_plan`が未設定の場合、調査計画を生成（LLM呼び出し）
3. `research_data`と`iteration_count`を評価
4. 次のアクションを決定:
   - `research`: 情報が不足している場合
   - `write`: 十分な情報が集まった場合
   - `end`: 最大イテレーション到達、または品質OKの場合

**実装例**:
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI

def supervisor_node(state: ResearchState) -> ResearchState:
    """Supervisorノード: 計画立案とルーティング"""
    
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    
    # 計画が未設定の場合、計画を生成
    if state["task_plan"] is None:
        plan = generate_plan(state, llm)
        state["task_plan"] = plan
    
    # ルーティング決定
    next_action = decide_next_action(state, llm)
    state["next_action"] = next_action
    
    return state
```

### 4.2 Researcherノード

**役割**: Web検索実行、結果の要約と整理

**入力**: `ResearchState`

**出力**: `ResearchState` (research_dataを更新)

**処理フロー**:
1. `task_plan`から検索クエリを取得
2. Tavily Search APIを呼び出し
3. 検索結果を`SearchResult`モデルに変換
4. `research_data`に追加（重複除去）
5. メッセージ履歴に検索結果を記録

**実装例**:
```python
from langchain_community.tools.tavily_search import TavilySearchResults

def researcher_node(state: ResearchState) -> ResearchState:
    """Researcherノード: Web検索と情報収集"""
    
    search_tool = TavilySearchResults(max_results=5)
    plan = state["task_plan"]
    
    new_results = []
    for query in plan.search_queries:
        results = search_tool.invoke({"query": query})
        for result in results:
            search_result = SearchResult(
                title=result.get("title", ""),
                summary=result.get("content", ""),
                url=result.get("url", ""),
                source="tavily"
            )
            new_results.append(search_result)
    
    # 重複除去とマージ
    existing_urls = {r.url for r in state["research_data"]}
    unique_results = [
        r for r in new_results 
        if r.url not in existing_urls
    ]
    
    state["research_data"].extend(unique_results)
    state["iteration_count"] += 1
    
    return state
```

### 4.3 Writerノード

**役割**: 収集情報の統合、レポートドラフト作成

**入力**: `ResearchState`

**出力**: `ResearchState` (current_draftを更新)

**処理フロー**:
1. `research_data`を統合・整理
2. LLMを使用してマークダウンレポートを生成
3. `current_draft`に保存
4. メッセージ履歴にドラフトを記録

**実装例**:
```python
def writer_node(state: ResearchState) -> ResearchState:
    """Writerノード: レポートドラフト作成"""
    
    llm = ChatOpenAI(model="gpt-4o", temperature=0.3)
    
    # 研究データをテキストに変換
    research_text = format_research_data(state["research_data"])
    
    # プロンプト構築
    prompt = ChatPromptTemplate.from_messages([
        ("system", writer_system_prompt),
        ("human", "テーマ: {theme}\n研究データ:\n{research_data}")
    ])
    
    chain = prompt | llm
    draft = chain.invoke({
        "theme": state["task_plan"].theme,
        "research_data": research_text
    })
    
    state["current_draft"] = draft.content
    return state
```

### 4.4 Reviewerノード

**役割**: ドラフトの品質評価、フィードバック生成

**入力**: `ResearchState`

**出力**: `ResearchState` (feedbackを更新、next_actionを設定)

**処理フロー**:
1. `current_draft`を評価
2. ファクトチェック（出典との整合性確認）
3. 情報の不足点を指摘
4. 品質判定:
   - 合格: `next_action = "end"`
   - 不合格: `feedback`に改善指示を記録、`next_action = "research"` or `"write"`

**実装例**:
```python
def reviewer_node(state: ResearchState) -> ResearchState:
    """Reviewerノード: ドラフト評価とフィードバック"""
    
    llm = ChatOpenAI(model="gpt-4o", temperature=0)
    
    # 評価プロンプト
    prompt = ChatPromptTemplate.from_messages([
        ("system", reviewer_system_prompt),
        ("human", """
        ドラフト:
        {draft}
        
        研究データ:
        {research_data}
        
        評価してください。
        """)
    ])
    
    chain = prompt | llm
    evaluation = chain.invoke({
        "draft": state["current_draft"],
        "research_data": format_research_data(state["research_data"])
    })
    
    # 評価結果をパース（JSON形式を想定）
    eval_result = parse_evaluation(evaluation.content)
    
    if eval_result["approved"]:
        state["next_action"] = "end"
        state["feedback"] = None
    else:
        state["feedback"] = eval_result["feedback"]
        state["next_action"] = eval_result["suggested_action"]  # "research" or "write"
    
    return state
```

## 5. エッジ/ルーティング設計

### 5.1 エッジ定義

LangGraphの`conditional_edges`を使用して、`next_action`に基づく動的ルーティングを実現。

```python
from langgraph.graph import StateGraph, END

def build_graph() -> StateGraph:
    """グラフ構築"""
    
    graph = StateGraph(ResearchState)
    
    # ノード追加
    graph.add_node("supervisor", supervisor_node)
    graph.add_node("researcher", researcher_node)
    graph.add_node("writer", writer_node)
    graph.add_node("reviewer", reviewer_node)
    
    # エントリーポイント
    graph.set_entry_point("supervisor")
    
    # Supervisorからのルーティング
    graph.add_conditional_edges(
        "supervisor",
        route_supervisor,
        {
            "research": "researcher",
            "write": "writer",
            "end": END
        }
    )
    
    # Researcher → Supervisor
    graph.add_edge("researcher", "supervisor")
    
    # Writer → Reviewer
    graph.add_edge("writer", "reviewer")
    
    # Reviewerからのルーティング
    graph.add_conditional_edges(
        "reviewer",
        route_reviewer,
        {
            "research": "researcher",
            "write": "writer",
            "end": END
        }
    )
    
    return graph.compile()

def route_supervisor(state: ResearchState) -> str:
    """Supervisorからのルーティング"""
    return state["next_action"]

def route_reviewer(state: ResearchState) -> str:
    """Reviewerからのルーティング"""
    # 最大イテレーション確認
    if state["iteration_count"] >= MAX_ITERATIONS:
        return "end"
    return state["next_action"]
```

### 5.2 Human-in-the-Loop実装

`interrupt_before`を使用して、特定ノードの実行前に人間の承認を待つ。

```python
# 人間介入が必要なポイントで中断
graph = build_graph()
compiled_graph = graph.compile(
    checkpointer=checkpointer,
    interrupt_before=["supervisor", "writer"]  # これらのノード前に中断
)

# 実行（中断時は待機）
config = {"configurable": {"thread_id": "thread-1"}}
result = compiled_graph.invoke(initial_state, config)

# 人間入力後の再開
compiled_graph.update_state(config, {"human_input": user_input})
result = compiled_graph.invoke(None, config)
```

## 6. ツール実装設計

### 6.1 Tavily検索ツール

```python
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.tools import tool

@tool
def tavily_search_tool(query: str, max_results: int = 5) -> List[Dict]:
    """
    Tavily Search APIを使用してWeb検索を実行
    
    Args:
        query: 検索クエリ
        max_results: 最大結果数
    
    Returns:
        検索結果のリスト
    """
    tavily = TavilySearchResults(max_results=max_results)
    return tavily.invoke({"query": query})
```

### 6.2 Webスクレイピングツール

```python
from langchain_community.tools import DuckDuckGoSearchRun
import requests
from bs4 import BeautifulSoup

@tool
def web_scraper_tool(url: str) -> str:
    """
    指定URLのコンテンツをスクレイピング
    
    Args:
        url: スクレイピング対象URL
    
    Returns:
        ページのテキストコンテンツ
    """
    try:
        response = requests.get(url, timeout=10)
        soup = BeautifulSoup(response.content, "html.parser")
        # メインコンテンツを抽出
        content = soup.find("main") or soup.find("article") or soup.find("body")
        return content.get_text(strip=True)
    except Exception as e:
        return f"Error scraping {url}: {str(e)}"
```

## 7. チェックポイント/永続化設計

### 7.1 MemorySaver（開発用）

```python
from langgraph.checkpoint.memory import MemorySaver

checkpointer = MemorySaver()
```

### 7.2 Redis（本番用）

```python
from langgraph.checkpoint.redis import RedisCheckpointer
import redis

redis_client = redis.Redis(host="localhost", port=6379, db=0)
checkpointer = RedisCheckpointer(redis_client)
```

### 7.3 チェックポイントの活用

```python
# グラフ実行時にチェックポイントを設定
config = {
    "configurable": {
        "thread_id": "unique-session-id",
        "checkpoint_ns": "research-agent"
    }
}

# 実行
result = compiled_graph.invoke(initial_state, config)

# 状態の復元
state = compiled_graph.get_state(config)
```

## 8. エラーハンドリング設計

### 8.1 リトライロジック

```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def researcher_node_with_retry(state: ResearchState) -> ResearchState:
    """リトライ機能付きResearcherノード"""
    try:
        return researcher_node(state)
    except Exception as e:
        logger.error(f"Researcher error: {e}")
        raise
```

### 8.2 最大イテレーション制御

```python
MAX_ITERATIONS = 5

def route_with_limit(state: ResearchState) -> str:
    """イテレーション制限付きルーティング"""
    if state["iteration_count"] >= MAX_ITERATIONS:
        logger.warning("Max iterations reached")
        return "end"
    return state["next_action"]
```

### 8.3 エラー時のフォールバック

```python
def safe_node_execution(node_func, state: ResearchState) -> ResearchState:
    """安全なノード実行（エラーハンドリング付き）"""
    try:
        return node_func(state)
    except Exception as e:
        logger.error(f"Node error: {e}")
        # エラーメッセージをステートに記録
        state["messages"].append(
            HumanMessage(content=f"Error: {str(e)}")
        )
        state["next_action"] = "end"  # エラー時は終了
        return state
```

## 9. プロンプト設計

### 9.1 Supervisorプロンプト

```python
SUPERVISOR_SYSTEM_PROMPT = """
あなたはリサーチエージェントのSupervisorです。
ユーザーのテーマに基づいて調査計画を立て、適切なWorkerにタスクを割り振ります。

役割:
1. テーマを分析し、調査観点を抽出
2. 検索クエリを生成
3. 現在の進捗を評価し、次のアクションを決定

次のアクションは以下のいずれかです:
- "research": 情報が不足している場合
- "write": 十分な情報が集まった場合
- "end": 最大イテレーション到達、または完了した場合

JSON形式で応答してください:
{
    "plan": {
        "theme": "...",
        "investigation_points": ["..."],
        "search_queries": ["..."],
        "plan_text": "..."
    },
    "next_action": "research" | "write" | "end",
    "reasoning": "..."
}
"""
```

### 9.2 Researcherプロンプト

```python
RESEARCHER_SYSTEM_PROMPT = """
あなたはResearcherです。
検索クエリに基づいてWeb検索を実行し、関連する情報を収集・整理します。

タスク:
1. 検索クエリを実行
2. 結果を関連性の高い順にソート
3. 重複を除去
4. 各結果を要約

検索結果は以下の形式で返してください:
- タイトル
- URL
- 要約（100文字程度）
- 関連性スコア（0-1）
"""
```

### 9.3 Writerプロンプト

```python
WRITER_SYSTEM_PROMPT = """
あなたはWriterです。
収集された情報を統合し、高品質なマークダウンレポートを作成します。

要件:
1. エグゼクティブサマリーを含める
2. 主要な発見を箇条書きで列挙
3. 詳細な分析を提供
4. すべての主張に出典（URL）を明記
5. マークダウン形式で出力

構造:
# タイトル
## Executive Summary
## Key Findings
## Detailed Analysis
## References
"""
```

### 9.4 Reviewerプロンプト

```python
REVIEWER_SYSTEM_PROMPT = """
あなたはReviewerです。
ドラフトの品質を評価し、改善点を指摘します。

評価観点:
1. ファクトチェック（出典との整合性）
2. 情報の網羅性
3. 論理的一貫性
4. 出典の正確性

JSON形式で応答してください:
{
    "approved": true | false,
    "feedback": "改善点の説明",
    "suggested_action": "research" | "write",
    "issues": [
        {
            "type": "fact_check" | "completeness" | "logic",
            "description": "...",
            "severity": "high" | "medium" | "low"
        }
    ]
}
"""
```

## 10. 設定管理

### 10.1 環境変数

```python
# config/settings.py

from pydantic_settings import BaseSettings

class Settings(BaseSettings):
    """アプリケーション設定"""
    
    # OpenAI
    OPENAI_API_KEY: str
    OPENAI_MODEL: str = "gpt-4o"
    
    # Tavily
    TAVILY_API_KEY: str
    
    # Redis（オプション）
    REDIS_HOST: str = "localhost"
    REDIS_PORT: int = 6379
    REDIS_DB: int = 0
    
    # 制限
    MAX_ITERATIONS: int = 5
    MAX_SEARCH_RESULTS: int = 10
    
    class Config:
        env_file = ".env"
```

## 11. 依存関係

### 11.1 requirements.txt

```
langchain>=0.1.0
langgraph>=0.2.0
langchain-openai>=0.1.0
langchain-community>=0.0.20
tavily-python>=0.3.0
pydantic>=2.0.0
pydantic-settings>=2.0.0
redis>=5.0.0
requests>=2.31.0
beautifulsoup4>=4.12.0
tenacity>=8.2.0
python-dotenv>=1.0.0
```

## 12. 実装上の注意点

### 12.1 LangChain 1.0の変更点

- `langchain`パッケージは統合パッケージとなり、個別の`langchain-*`パッケージを使用
- `ChatOpenAI`は`langchain_openai`からインポート
- ツールは`@tool`デコレータを使用
- プロンプトは`ChatPromptTemplate`を使用

### 12.2 LangGraphのベストプラクティス

- ステートは`TypedDict`で型安全に定義
- `Annotated`と`add_messages`でメッセージ履歴を管理
- チェックポイントを使用して状態を永続化
- `interrupt_before`で人間介入ポイントを設定

### 12.3 パフォーマンス最適化

- 検索結果のキャッシュ（重複検索を避ける）
- 並列検索の実装（複数クエリを同時実行）
- ストリーミング出力（長いレポート生成時）

### 12.4 セキュリティ

- APIキーは環境変数で管理
- ユーザー入力のサニタイゼーション
- URL検証（スクレイピング前）

## 13. テスト戦略

### 13.1 ユニットテスト

- 各ノードの個別テスト
- ツールの動作確認
- ステート遷移のテスト

### 13.2 統合テスト

- グラフ全体の実行フロー
- エラーハンドリングの確認
- チェックポイントの動作確認

### 13.3 エンドツーエンドテスト

- 実際のテーマでのレポート生成
- 品質評価
- パフォーマンス測定

## 14. デプロイメント

### 14.1 ローカル実行

```python
# examples/example_usage.py

from src.graph.graph_builder import build_graph
from src.config.settings import Settings

settings = Settings()
graph = build_graph(settings)

initial_state = {
    "messages": [HumanMessage(content="LangGraphについて調査してください")],
    "task_plan": None,
    "research_data": [],
    "current_draft": None,
    "feedback": None,
    "iteration_count": 0,
    "next_action": "research",
    "human_input_required": False,
    "human_input": None
}

result = graph.invoke(initial_state)
```

### 14.2 API化（FastAPI）

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

class ResearchRequest(BaseModel):
    theme: str
    max_iterations: int = 5

@app.post("/research")
async def research(request: ResearchRequest):
    graph = build_graph()
    # 実行ロジック
    return {"status": "completed", "report": "..."}
```

---

## 付録A: 用語集

- **StateGraph**: LangGraphのグラフ構造。ノードとエッジで構成
- **TypedDict**: Pythonの型ヒント。ステートの型定義に使用
- **Checkpointer**: グラフの状態を永続化する機能
- **Human-in-the-Loop**: 人間の承認や入力を受け付ける機能
- **Conditional Edges**: 条件に基づいて動的にルーティングするエッジ

## 付録B: 参考資料

- [LangGraph Documentation](https://langchain-ai.github.io/langgraph/)
- [LangChain 1.0 Migration Guide](https://python.langchain.com/docs/versions/)
- [Tavily API Documentation](https://docs.tavily.com/)

