# プロンプト設計書：AI コーディング用

## 1. ドキュメント情報

- **文書名**: プロンプト設計書（AI コーディング用）
- **バージョン**: 1.1
- **作成日**: 2024-12-27
- **最終更新日**: 2025-02-01
- **対象システム**: LangGraph搭載 自律型リサーチエージェント
- **目的**: AIにコード生成を依頼する際のプロンプトテンプレートとガイドライン

---

## 2. プロンプト設計の原則

### 2.1 基本原則

1. **明確性**: 要求を明確に、曖昧さを排除
2. **構造化**: 段階的に情報を提供（コンテキスト → 要件 → 制約 → 出力形式）
3. **具体性**: 具体例を含める
4. **参照**: 関連する設計書や既存コードへの参照を含める
5. **検証可能性**: 生成されたコードが検証可能な形式で出力

### 2.2 プロンプト構造テンプレート

```
# コンテキスト
- プロジェクトの概要
- 関連する設計書への参照
- 既存コードとの関係

# 要件
- 実装すべき機能の詳細
- 入力・出力仕様
- 処理フロー

# 技術的制約
- 使用するライブラリ・フレームワーク
- バージョン要件
- コーディング規約

# 出力形式
- ファイル構造
- 関数・クラスのシグネチャ
- テスト要件

# 注意事項
- 実装上の注意点
- エラーハンドリング要件
- パフォーマンス要件
```

---

## 3. モジュール別プロンプトテンプレート

### 3.1 F001: ステート管理機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、LangGraphのステート管理機能を実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 3章、詳細設計書 3.1節
- ファイルパス: `src/graph/state.py`

## 要件
1. `ResearchState`というTypedDictを定義
2. LangGraph 1.0以上、LangChain 1.0以上を使用
3. 以下のフィールドを含める:
   - messages: Annotated[List[BaseMessage], add_messages]
   - task_plan: Optional[ResearchPlan]
   - research_data: List[SearchResult]
   - current_draft: Optional[str]
   - feedback: Optional[str]
   - iteration_count: int
   - next_action: Literal["research", "write", "review", "end"]
   - human_input_required: bool
   - human_input: Optional[str]

## 技術的制約
- Python 3.10以上
- 型ヒントを完全に記述
- docstringを日本語で記述
- Pydanticモデル（ResearchPlan, SearchResult）は別ファイルからインポート

## 出力形式
```python
from typing import TypedDict, List, Optional, Literal, Annotated
from langchain_core.messages import BaseMessage
from langgraph.graph.message import add_messages
from src.schemas.data_models import ResearchPlan, SearchResult

class ResearchState(TypedDict):
    """リサーチエージェントの共有ステート"""
    # 実装...
```

## 注意事項
- `add_messages`を使用してメッセージを自動マージ
- すべてのフィールドに型ヒントを付与
- ドキュメント文字列を充実させる
```

---

### 3.2 F002: Supervisorノード機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、Supervisorノードを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 4.1節、詳細設計書 3.2節
- ファイルパス: `src/nodes/supervisor.py`
- 依存: `src/graph/state.py`, `src/schemas/data_models.py`, `src/prompts/supervisor_prompt.py`

## 要件
1. `supervisor_node(state: ResearchState) -> ResearchState`関数を実装
2. 処理フロー:
   a. メッセージ履歴からユーザーのテーマを抽出
   b. task_planが未設定の場合、調査計画を生成（LLM呼び出し）
   c. 現在の進捗を評価（research_dataの量と質）
   d. 次のアクションを決定（research/write/end）
   e. 判断理由をメッセージに記録

3. サブ関数:
   - `extract_user_message(messages: List[BaseMessage]) -> str`
   - `extract_theme(message: str) -> str`
   - `generate_research_plan(theme: str, state: ResearchState, llm: ChatOpenAI) -> ResearchPlan`
   - `evaluate_progress(state: ResearchState) -> Dict[str, Any]`
   - `decide_next_action(state: ResearchState, progress: Dict, llm: ChatOpenAI) -> Tuple[str, str]`

## 技術的制約
- LangChain 1.0以上: `langchain_openai.ChatOpenAI`を使用
- プロンプト: `ChatPromptTemplate.from_messages()`を使用
- JSON解析: LLMの応答をJSON形式で受け取り、Pydanticモデルに変換
- エラーハンドリング: try-exceptでエラーをキャッチし、ステートに記録

## 出力形式
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage
from src.graph.state import ResearchState
from src.schemas.data_models import ResearchPlan
from src.prompts.supervisor_prompt import SUPERVISOR_PLANNING_PROMPT, SUPERVISOR_ROUTING_PROMPT
import logging

logger = logging.getLogger(__name__)

def supervisor_node(state: ResearchState) -> ResearchState:
    """Supervisorノード: 計画立案とルーティング決定"""
    # 実装...
```

## 注意事項
- LLM呼び出しはリトライロジックを含める（tenacity使用）
- JSONパースエラー時は再生成を試行
- 最大イテレーション数を考慮したルーティング決定
- ログ出力を適切に記述
```

---

### 3.3 F003: Researcherノード機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、Researcherノードを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 4.2節、詳細設計書 3.3節
- ファイルパス: `src/nodes/researcher.py`
- 依存: `src/graph/state.py`, `src/tools/search_tool.py`, `src/schemas/data_models.py`

## 要件
1. `researcher_node(state: ResearchState) -> ResearchState`関数を実装
2. 処理フロー:
   a. task_planから検索クエリを取得
   b. 各クエリに対してTavily検索を実行（tavily_search_tool使用）
   c. 検索結果をSearchResultモデルに変換
   d. 重複除去（URLベース）
   e. research_dataに追加
   f. メッセージに結果を記録

3. エラーハンドリング:
   - 検索エラー時はエラーログを記録し、次のクエリに進む
   - 無効なURLはスキップ

## 技術的制約
- Tavily検索ツール: `src/tools/search_tool.tavily_search_tool`を使用
- 最大結果数: 設定ファイルから取得（デフォルト5件/クエリ）
- 重複除去: 既存のresearch_dataのURLセットと比較
- ログ: 検索結果の件数を記録

## 出力形式
```python
from langchain_core.messages import AIMessage
from src.graph.state import ResearchState
from src.schemas.data_models import SearchResult
from src.tools.search_tool import tavily_search_tool
from src.config.settings import Settings
import logging

logger = logging.getLogger(__name__)
settings = Settings()

def researcher_node(state: ResearchState) -> ResearchState:
    """Researcherノード: Web検索と情報収集"""
    # 実装...
```

## 注意事項
- 検索結果の要約は500文字に制限
- 各検索クエリのエラーは他のクエリに影響しない
- iteration_countをインクリメント
- 検索結果のサマリーをメッセージに追加
```

---

### 3.4 F004: Writerノード機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、Writerノードを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 4.3節、詳細設計書 3.4節
- ファイルパス: `src/nodes/writer.py`
- 依存: `src/graph/state.py`, `src/prompts/writer_prompt.py`

## 要件
1. `writer_node(state: ResearchState) -> ResearchState`関数を実装
2. 処理フロー:
   a. research_dataを構造化テキストに変換（format_research_data関数）
   b. フィードバックがある場合は考慮
   c. LLMにレポート生成を依頼（プロンプトテンプレート使用）
   d. マークダウン形式で出力
   e. current_draftに保存

3. サブ関数:
   - `format_research_data(research_data: List[SearchResult]) -> str`
   - `extract_markdown_content(response_content: str) -> str`

## 技術的制約
- LLM: GPT-4o、temperature=0.3
- プロンプト: `ChatPromptTemplate.from_messages()`を使用
- マークダウン抽出: コードブロックや余分なテキストを除去
- エラーハンドリング: LLM呼び出しエラー時はリトライ

## 出力形式
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage
from src.graph.state import ResearchState
from src.prompts.writer_prompt import WRITER_SYSTEM_PROMPT, WRITER_USER_PROMPT
import logging
import re

logger = logging.getLogger(__name__)

def writer_node(state: ResearchState) -> ResearchState:
    """Writerノード: レポートドラフト作成"""
    # 実装...
```

## 注意事項
- フィードバックがある場合はプロンプトに含める
- マークダウン形式の検証を行う
- ドラフトの長さをログに記録
- すべての主張に出典URLを明記するようプロンプトに含める
```

---

### 3.5 F005: Reviewerノード機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、Reviewerノードを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 4.4節、詳細設計書 3.5節
- ファイルパス: `src/nodes/reviewer.py`
- 依存: `src/graph/state.py`, `src/prompts/reviewer_prompt.py`

## 要件
1. `reviewer_node(state: ResearchState) -> ResearchState`関数を実装
2. 処理フロー:
   a. ドラフトの存在確認
   b. ファクトチェック（出典との整合性）
   c. 網羅性チェック（計画との整合性）
   d. 論理的一貫性チェック
   e. 総合評価とフィードバック生成
   f. 次のアクション決定（approved: "end", rejected: "research" or "write"）

3. 評価結果のパース:
   - LLMの応答をJSON形式で受け取る
   - 評価結果をパースして、approved, feedback, suggested_actionを取得

## 技術的制約
- LLM: GPT-4o、temperature=0（厳密な評価のため）
- JSON形式の応答を期待
- 評価結果のパースエラー時は再評価を試行
- 合格基準: 総合スコア >= 0.8 かつ ファクトチェックスコア >= 0.9

## 出力形式
```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import AIMessage
from src.graph.state import ResearchState
from src.prompts.reviewer_prompt import REVIEWER_SYSTEM_PROMPT
import json
import logging

logger = logging.getLogger(__name__)

def reviewer_node(state: ResearchState) -> ResearchState:
    """Reviewerノード: ドラフト評価とフィードバック"""
    # 実装...

def parse_evaluation_result(evaluation_text: str) -> Dict[str, Any]:
    """評価結果をパース"""
    # 実装...
```

## 注意事項
- ドラフトがNoneの場合はエラーを発生
- JSONパースエラー時は再評価を試行（最大3回）
- 評価結果をメッセージに記録
- 次のアクションを適切に設定
```

---

### 3.6 F006: グラフ構築・ルーティング機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、LangGraphのグラフ構築とルーティング機能を実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 5章、詳細設計書 3.6節
- ファイルパス: `src/graph/graph_builder.py`, `src/graph/edges.py`
- 依存: `src/graph/state.py`, `src/nodes/*.py`

## 要件
1. `build_graph()`関数を実装（`src/graph/graph_builder.py`）
   - StateGraphを作成
   - 4つのノードを追加（supervisor, researcher, writer, reviewer）
   - エントリーポイントを設定
   - エッジを追加（条件分岐含む）
   - コンパイルして返す

2. ルーティング関数を実装（`src/graph/edges.py`）
   - `route_supervisor(state: ResearchState) -> str`
   - `route_reviewer(state: ResearchState) -> str`

3. グラフ構造:
   ```
   START → supervisor → [conditional] → researcher/writer/end
                                       ↓
                                 researcher → supervisor
                                       ↓
                                 writer → reviewer
                                       ↓
                                 reviewer → [conditional] → researcher/writer/end
   ```

## 技術的制約
- LangGraph 1.0以上: `StateGraph`, `END`, `conditional_edges`を使用
- チェックポイント: オプションで受け取る
- interrupt_before: オプションで人間介入ポイントを設定
- 型ヒントを完全に記述

## 出力形式
```python
# src/graph/graph_builder.py
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.base import BaseCheckpointSaver
from src.graph.state import ResearchState
from src.nodes.supervisor import supervisor_node
from src.nodes.researcher import researcher_node
from src.nodes.writer import writer_node
from src.nodes.reviewer import reviewer_node
from src.graph.edges import route_supervisor, route_reviewer
from typing import Optional, List

def build_graph(
    checkpointer: Optional[BaseCheckpointSaver] = None,
    interrupt_before: Optional[List[str]] = None
) -> CompiledGraph:
    """グラフを構築してコンパイル"""
    # 実装...

# src/graph/edges.py
from src.graph.state import ResearchState
from src.config.settings import Settings
import logging

logger = logging.getLogger(__name__)
settings = Settings()

def route_supervisor(state: ResearchState) -> str:
    """Supervisorからのルーティング"""
    # 実装...

def route_reviewer(state: ResearchState) -> str:
    """Reviewerからのルーティング"""
    # 実装...
```

## 注意事項
- エッジの順序に注意（条件分岐の前に固定エッジを追加）
- 最大イテレーション確認をroute_reviewerに含める
- コンパイル時にcheckpointerとinterrupt_beforeを設定
```

---

### 3.7 F007: 検索ツール機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、Tavily検索ツールを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 6.1節、詳細設計書 3.7節
- ファイルパス: `src/tools/search_tool.py`
- 依存: `langchain_community.tools.tavily_search`

## 要件
1. `tavily_search_tool`関数を実装
   - LangChainの`@tool`デコレータを使用
   - Tavily Search APIを呼び出し
   - リトライロジックを含める（tenacity使用）
   - エラーハンドリングを実装

2. 入力:
   - query: str（検索クエリ）
   - max_results: int（最大結果数、デフォルト5）

3. 出力:
   - List[Dict[str, Any]]（検索結果のリスト）

## 技術的制約
- LangChain 1.0以上: `langchain_core.tools.tool`デコレータを使用
- Tavily: `langchain_community.tools.tavily_search.TavilySearchResults`を使用
- リトライ: tenacityを使用（最大3回、指数バックオフ）
- APIキー: 環境変数`TAVILY_API_KEY`から取得

## 出力形式
```python
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.tools import tool
from tenacity import retry, stop_after_attempt, wait_exponential, retry_if_exception_type
import os
import logging

logger = logging.getLogger(__name__)

@tool
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def tavily_search_tool(query: str, max_results: int = 5) -> List[Dict[str, Any]]:
    """
    Tavily Search APIを使用してWeb検索を実行
    
    Args:
        query: 検索クエリ
        max_results: 最大結果数（1-20推奨）
    
    Returns:
        検索結果のリスト
    """
    # 実装...
```

## 注意事項
- クエリのバリデーション（空文字チェック）
- max_resultsの範囲チェック（1-20）
- APIキー未設定時のエラーハンドリング
- タイムアウト設定（10秒）
```

---

### 3.8 F008: スクレイピングツール機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、Webスクレイピングツールを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 6.2節、詳細設計書 3.8節
- ファイルパス: `src/tools/scraper_tool.py`
- 依存: `requests`, `beautifulsoup4`

## 要件
1. `web_scraper_tool`関数を実装
   - LangChainの`@tool`デコレータを使用
   - 指定URLのコンテンツをスクレイピング
   - メインコンテンツを抽出
   - テキストをクリーンアップ

2. サブ関数:
   - `is_valid_url(url: str) -> bool`: URL検証
   - `extract_main_content(soup: BeautifulSoup) -> str`: メインコンテンツ抽出
   - `clean_text(text: str) -> str`: テキストクリーンアップ

3. コンテンツ抽出の優先順位:
   - <main>タグ
   - <article>タグ
   - <div class="content">等
   - <body>タグ（フォールバック）

## 技術的制約
- requests: HTTPリクエスト実行
- BeautifulSoup4: HTMLパース
- タイムアウト: 10秒
- User-Agent: "Mozilla/5.0 (Research Agent Bot)"

## 出力形式
```python
from langchain_core.tools import tool
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import re
import logging

logger = logging.getLogger(__name__)

@tool
def web_scraper_tool(url: str) -> str:
    """
    指定URLのコンテンツをスクレイピング
    
    Args:
        url: スクレイピング対象URL
    
    Returns:
        ページのテキストコンテンツ
    """
    # 実装...

def is_valid_url(url: str) -> bool:
    """URL検証"""
    # 実装...

def extract_main_content(soup: BeautifulSoup) -> str:
    """メインコンテンツを抽出"""
    # 実装...

def clean_text(text: str) -> str:
    """テキストをクリーンアップ"""
    # 実装...
```

## 注意事項
- URL検証を実施（urlparse使用）
- HTTPエラー時の適切なエラーハンドリング
- スクリプトとスタイルタグを除去
- テキストの正規化（余分な空白除去）
```

---

### 3.9 F009: チェックポイント機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、チェックポイント機能を実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 7章、詳細設計書 3.9節
- ファイルパス: `src/utils/checkpointer.py`
- 依存: `langgraph.checkpoint.memory`, `langgraph.checkpoint.redis`

## 要件
1. `create_checkpointer()`関数を実装
   - checkpointer_typeに応じてMemorySaverまたはRedisCheckpointerを作成
   - Redis設定は環境変数または引数から取得

2. 補助関数:
   - `save_checkpoint()`: 明示的なチェックポイント保存（オプション）
   - `load_checkpoint()`: チェックポイントから状態を復元

## 技術的制約
- MemorySaver: 開発用（メモリ内保存）
- RedisCheckpointer: 本番用（Redisに保存）
- Redis: redisライブラリを使用
- 設定: Settingsクラスから取得

## 出力形式
```python
from langgraph.checkpoint.memory import MemorySaver
from langgraph.checkpoint.redis import RedisCheckpointer
from langgraph.graph import CompiledGraph
from langgraph.checkpoint.base import BaseCheckpointSaver
import redis
from typing import Optional, Dict
from src.config.settings import Settings
from src.graph.state import ResearchState

def create_checkpointer(
    checkpointer_type: str = "memory",
    redis_config: Optional[Dict] = None
) -> BaseCheckpointSaver:
    """
    チェックポインターを作成
    
    Args:
        checkpointer_type: "memory" または "redis"
        redis_config: Redis設定（redis使用時）
    
    Returns:
        Checkpointerインスタンス
    """
    # 実装...

def save_checkpoint(
    graph: CompiledGraph,
    config: Dict,
    state: ResearchState
) -> None:
    """チェックポイントを保存（明示的）"""
    # 実装...

def load_checkpoint(
    graph: CompiledGraph,
    config: Dict
) -> Optional[ResearchState]:
    """チェックポイントから状態を復元"""
    # 実装...
```

## 注意事項
- checkpointer_typeのバリデーション
- Redis接続エラー時のハンドリング
- 設定の優先順位（引数 > 環境変数 > デフォルト）
```

---

### 3.10 F010: Human-in-the-Loop機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、Human-in-the-Loop機能を実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 5.2節、詳細設計書 3.10節
- ファイルパス: `src/utils/human_in_loop.py`
- 依存: `src/graph/graph_builder.py`

## 要件
1. `setup_human_intervention()`関数を実装
   - 人間介入ポイントを設定（補助的処理）

2. `wait_for_human_input()`関数を実装
   - 人間入力を待つ（実際の実装ではUI/API経由）

3. `resume_with_input()`関数を実装
   - 人間入力でグラフを再開

## 技術的制約
- interrupt_beforeはgraph_builderで設定済み
- 状態の確認: `graph.get_state(config)`
- 状態の更新: `graph.update_state(config, updates)`
- 再開: `graph.invoke(None, config)`

## 出力形式
```python
from langgraph.graph import CompiledGraph
from src.graph.state import ResearchState
from typing import List, Optional, Dict

def setup_human_intervention(
    graph: CompiledGraph,
    interrupt_nodes: List[str]
) -> CompiledGraph:
    """
    人間介入ポイントを設定
    
    注意: interrupt_beforeは既にgraph_builderで設定済み
    """
    # 補助的な処理があれば実装...

def wait_for_human_input(
    graph: CompiledGraph,
    config: Dict
) -> Optional[str]:
    """
    人間入力を待つ
    
    Returns:
        人間からの入力文字列、またはNone（タイムアウト）
    """
    # 実装...

def resume_with_input(
    graph: CompiledGraph,
    config: Dict,
    human_input: str
) -> ResearchState:
    """
    人間入力でグラフを再開
    
    Args:
        graph: コンパイル済みグラフ
        config: 設定
        human_input: 人間からの入力
    
    Returns:
        更新されたステート
    """
    # 実装...
```

## 注意事項
- 実際のUI実装は別途必要
- タイムアウト処理を考慮
- 状態の確認と更新のタイミングに注意
```

---

### 3.11 F011: エラーハンドリング機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、エラーハンドリング機能を実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 8章、詳細設計書 3.11節
- ファイルパス: `src/utils/retry.py`, `src/utils/error_handler.py`
- 依存: `tenacity`

## 要件
1. リトライデコレータを実装（`src/utils/retry.py`）
   - `call_llm_with_retry()`: LLM呼び出し用
   - `search_with_retry()`: 検索API用

2. エラーハンドリングデコレータを実装（`src/utils/error_handler.py`）
   - `handle_node_errors()`: ノード実行時のエラーをハンドル

## 技術的制約
- tenacity: リトライライブラリ
- 指数バックオフ: wait_exponential使用
- 最大リトライ回数: 3回
- エラーログ: loggingを使用

## 出力形式
```python
# src/utils/retry.py
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)
import openai
import requests
import logging

logger = logging.getLogger(__name__)

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    retry=retry_if_exception_type(openai.APIError)
)
def call_llm_with_retry(llm, prompt):
    """LLM呼び出し（リトライ付き）"""
    # 実装...

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=8),
    retry=retry_if_exception_type(requests.RequestException)
)
def search_with_retry(tool, query):
    """検索実行（リトライ付き）"""
    # 実装...

# src/utils/error_handler.py
from functools import wraps
import logging
from src.graph.state import ResearchState
from langchain_core.messages import AIMessage

logger = logging.getLogger(__name__)

def handle_node_errors(node_func):
    """ノード実行時のエラーをハンドルするデコレータ"""
    # 実装...
```

## 注意事項
- リトライ条件を適切に設定
- エラーログに詳細情報を含める
- ノードエラー時はステートにエラーを記録
```

---

### 3.12 F012: ロギング・可観測性機能

#### プロンプトテンプレート

```
以下の仕様に基づいて、ロギング・可観測性機能を実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 12.3節、詳細設計書 3.12節
- ファイルパス: `src/utils/logger.py`
- 依存: `logging`, `langsmith`（オプション）

## 要件
1. `setup_logger()`関数を実装
   - ロガーを設定（レベル、フォーマット、ハンドラー）

2. 補助関数:
   - `log_node_execution()`: ノード実行をログに記録
   - `log_llm_call()`: LLM呼び出しをログに記録

3. LangSmith連携（オプション）:
   - `setup_langsmith()`: LangSmithのトレーシングを設定

## 技術的制約
- logging: Python標準ライブラリ
- ログレベル: DEBUG, INFO, WARNING, ERROR
- フォーマット: タイムスタンプ、名前、レベル、メッセージ
- LangSmith: 環境変数から設定を読み込む

## 出力形式
```python
import logging
from datetime import datetime
from typing import Dict, Any
from src.graph.state import ResearchState
import os

def setup_logger(name: str = "research_agent") -> logging.Logger:
    """
    ロガーを設定
    
    Returns:
        設定済みロガー
    """
    # 実装...

def log_node_execution(
    logger: logging.Logger,
    node_name: str,
    state: ResearchState,
    duration: float
):
    """ノード実行をログに記録"""
    # 実装...

def log_llm_call(
    logger: logging.Logger,
    prompt: str,
    response: str,
    tokens_used: int
):
    """LLM呼び出しをログに記録"""
    # 実装...

def setup_langsmith():
    """LangSmithのトレーシングを設定"""
    # 実装...
```

## 注意事項
- ログレベルを適切に設定
- 機密情報（APIキー等）をログに出力しない
- パフォーマンス情報を含める
```

---

### 3.13 データモデル（Pydantic）

#### プロンプトテンプレート

```
以下の仕様に基づいて、データモデルを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 3.2節、詳細設計書 3.1.4節
- ファイルパス: `src/schemas/data_models.py`
- 依存: `pydantic`

## 要件
1. `ResearchPlan`クラスを実装
   - theme: str
   - investigation_points: List[str]
   - search_queries: List[str]
   - plan_text: str
   - created_at: datetime

2. `SearchResult`クラスを実装
   - title: str
   - summary: str
   - url: str
   - source: str = "tavily"
   - published_date: Optional[str] = None
   - relevance_score: Optional[float] = None

## 技術的制約
- Pydantic 2.0以上
- 型ヒントを完全に記述
- Field()を使用してデフォルト値を設定
- docstringを日本語で記述

## 出力形式
```python
from pydantic import BaseModel, Field
from datetime import datetime
from typing import List, Optional

class ResearchPlan(BaseModel):
    """調査計画モデル"""
    # 実装...

class SearchResult(BaseModel):
    """検索結果モデル"""
    # 実装...
```

## 注意事項
- JSONシリアライゼーションを考慮
- バリデーションルールを適切に設定
- 例（example）を含める（オプション）
```

---

### 3.14 設定管理

#### プロンプトテンプレート

```
以下の仕様に基づいて、設定管理機能を実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 10章、詳細設計書 3.1.8節
- ファイルパス: `src/config/settings.py`
- 依存: `pydantic-settings`

## 要件
1. `Settings`クラスを実装
   - OpenAI設定（APIキー、モデル名）
   - Tavily設定（APIキー）
   - Redis設定（ホスト、ポート、DB）
   - 制限設定（最大イテレーション、最大検索結果数）

2. 環境変数から読み込む
   - .envファイルをサポート
   - デフォルト値を設定

## 技術的制約
- Pydantic Settings 2.0以上
- 環境変数の命名規則: 大文字、アンダースコア区切り
- .envファイル: python-dotenvを使用

## 出力形式
```python
from pydantic_settings import BaseSettings
from typing import Optional

class Settings(BaseSettings):
    """アプリケーション設定"""
    # OpenAI
    OPENAI_API_KEY: str
    OPENAI_MODEL: str = "gpt-4o"
    
    # Tavily
    TAVILY_API_KEY: str
    
    # Redis（オプション）
    REDIS_HOST: str = "localhost"
    REDIS_PORT: int = 6379
    REDIS_DB: int = 0
    
    # 制限
    MAX_ITERATIONS: int = 5
    MAX_SEARCH_RESULTS: int = 10
    MAX_RESULTS_PER_QUERY: int = 5
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"
```

## 注意事項
- 必須項目（APIキー）のバリデーション
- デフォルト値の適切な設定
- 環境変数のドキュメント化
```

---

### 3.15 プロンプトテンプレートファイル

#### プロンプトテンプレート

```
以下の仕様に基づいて、プロンプトテンプレートファイルを実装してください。

## コンテキスト
- プロジェクト: LangGraph搭載 自律型リサーチエージェント
- 参照文書: 基本設計書 9章、詳細設計書 3.4.6節、3.5.6節
- ファイルパス: `src/prompts/supervisor_prompt.py`, `src/prompts/writer_prompt.py`, `src/prompts/reviewer_prompt.py`

## 要件
1. Supervisorプロンプト（`src/prompts/supervisor_prompt.py`）
   - 計画生成用プロンプト
   - ルーティング決定用プロンプト

2. Writerプロンプト（`src/prompts/writer_prompt.py`）
   - システムプロンプト
   - ユーザープロンプトテンプレート

3. Reviewerプロンプト（`src/prompts/reviewer_prompt.py`）
   - システムプロンプト
   - 評価用プロンプトテンプレート

## 技術的制約
- プロンプトは文字列定数として定義
- フォーマット文字列（f-stringまたは.format()）を使用
- JSON形式の出力を指定

## 出力形式
```python
# src/prompts/supervisor_prompt.py
SUPERVISOR_PLANNING_PROMPT = """
あなたはリサーチエージェントのSupervisorです。
ユーザーのテーマに基づいて調査計画を立ててください。

# 要件
1. テーマを分析し、調査観点を抽出
2. 検索クエリを生成（3-7個）
3. 計画テキストを作成

# 出力形式
JSON形式で応答してください:
{{
    "theme": "{theme}",
    "investigation_points": ["観点1", "観点2", ...],
    "search_queries": ["クエリ1", "クエリ2", ...],
    "plan_text": "計画の説明文"
}}
"""

SUPERVISOR_ROUTING_PROMPT = """
現在の進捗を評価し、次のアクションを決定してください。

# 現在の状態
- 収集データ数: {data_count}
- データ品質スコア: {data_quality}
- イテレーション回数: {iteration_count}

# 次のアクション
- "research": 情報が不足している場合
- "write": 十分な情報が集まった場合
- "end": 最大イテレーション到達、または完了した場合

JSON形式で応答してください:
{{
    "next_action": "research" | "write" | "end",
    "reasoning": "判断理由"
}}
"""

# src/prompts/writer_prompt.py
WRITER_SYSTEM_PROMPT = """
あなたはWriterです。
収集された情報を統合し、高品質なマークダウンレポートを作成します。

# 要件
1. エグゼクティブサマリー（200-300文字）を含める
2. 主要な発見を3-5個の箇条書きで列挙
3. 詳細な分析を提供（各観点について説明）
4. すべての主張に出典URLを明記 [^1]
5. マークダウン形式で出力

# 構造
# {テーマ}

## Executive Summary
{サマリー}

## Key Findings
{箇条書き}

## Detailed Analysis
{詳細分析}

## References
[^1]: {URL1}
[^2]: {URL2}
...
"""

WRITER_USER_PROMPT = """
テーマ: {theme}

調査観点:
{investigation_points}

収集した情報:
{research_data}

{feedback}
"""

# src/prompts/reviewer_prompt.py
REVIEWER_SYSTEM_PROMPT = """
あなたはReviewerです。
ドラフトの品質を評価し、改善点を指摘します。

# 評価観点
1. ファクトチェック（出典との整合性）- 重み40%
2. 網羅性（計画との整合性）- 重み30%
3. 論理的一貫性 - 重み20%
4. 形式・構造 - 重み10%

# 合格基準
- 総合スコア >= 0.8
- ファクトチェックスコア >= 0.9

JSON形式で応答してください:
{{
    "approved": true | false,
    "overall_score": 0.0-1.0,
    "scores": {{
        "fact_check": 0.0-1.0,
        "completeness": 0.0-1.0,
        "logic": 0.0-1.0,
        "format": 0.0-1.0
    }},
    "feedback": "改善点の説明",
    "suggested_action": "research" | "write",
    "issues": [
        {{
            "type": "fact_check" | "completeness" | "logic" | "format",
            "severity": "high" | "medium" | "low",
            "description": "...",
            "location": "..."
        }}
    ]
}}
"""

REVIEWER_USER_PROMPT = """
ドラフト:
{draft}

研究データ:
{research_data}

調査計画:
{task_plan}

評価してください。
"""
```

## 注意事項
- プロンプトは明確で具体的に
- JSON形式の出力を厳密に指定
- 例を含める（可能な場合）
- 日本語と英語の混在を考慮
```

---

## 4. プロンプト使用ガイドライン

### 4.1 プロンプトの段階的実装

1. **第一段階**: 基本構造の実装
   - ファイル構造、インポート、基本的な関数シグネチャ

2. **第二段階**: コアロジックの実装
   - 主要な処理フロー、ビジネスロジック

3. **第三段階**: エラーハンドリングと最適化
   - リトライロジック、エラーハンドリング、パフォーマンス改善

### 4.2 プロンプトのカスタマイズ

各プロンプトテンプレートは、以下の点でカスタマイズ可能：

- **詳細度**: より詳細な仕様を追加
- **例**: 具体例を追加
- **制約**: 追加の制約を指定
- **出力形式**: 異なる出力形式を要求

### 4.3 プロンプトの検証

生成されたコードは以下の観点で検証：

1. **機能性**: 要件を満たしているか
2. **型安全性**: 型ヒントが適切か
3. **エラーハンドリング**: 適切にエラーを処理しているか
4. **ドキュメント**: docstringが充実しているか
5. **テスト**: テスト可能な構造か

---

## 5. 使用例

### 5.1 基本的な使用例

```
以下のプロンプトテンプレートを使用して、Supervisorノードを実装してください。

[3.2 F002: Supervisorノード機能のプロンプトテンプレートを貼り付け]

追加要件:
- ログ出力を追加
- エラーメッセージを日本語で出力
```

### 5.2 段階的実装の例

```
第一段階: Supervisorノードの基本構造を実装してください。
- 関数シグネチャ
- 基本的なインポート
- ドキュメント文字列

[3.2のプロンプトテンプレートの一部を使用]

第二段階: 計画生成ロジックを実装してください。
- generate_research_plan関数の詳細実装
- LLM呼び出し
- JSONパース

第三段階: エラーハンドリングとリトライを追加してください。
- リトライロジック
- エラーハンドリング
- ログ出力
```

### 5.3 統合実装の例

```
以下の複数のモジュールを統合して実装してください。

1. ステート管理機能（F001）
2. Supervisorノード機能（F002）
3. グラフ構築機能（F006）

各モジュール間の依存関係を考慮し、適切にインポートしてください。
```

---

## 6. ベストプラクティス

### 6.1 プロンプト作成時の注意点

1. **明確な指示**: 「実装してください」ではなく「どのように実装するか」を明確に
2. **具体例**: 可能な限り具体例を含める
3. **制約の明示**: 技術的制約を明確に記述
4. **出力形式**: 期待する出力形式を指定

### 6.2 コード生成後の確認事項

1. **インポート**: 必要なライブラリがインポートされているか
2. **型ヒント**: すべての関数に型ヒントが付いているか
3. **エラーハンドリング**: 適切なエラーハンドリングが実装されているか
4. **ログ**: 適切なログ出力が実装されているか
5. **ドキュメント**: docstringが充実しているか

### 6.3 反復的改善

1. **第一版**: 基本機能を実装
2. **レビュー**: コードレビューとテスト
3. **改善**: フィードバックに基づいて改善
4. **最適化**: パフォーマンスとコード品質の向上

---

## 7. トラブルシューティング

### 7.1 よくある問題と解決策

| 問題 | 原因 | 解決策 |
|------|------|--------|
| インポートエラー | パスが間違っている | 相対インポートと絶対インポートを確認 |
| 型エラー | 型ヒントが不完全 | すべての関数に型ヒントを追加 |
| 実行時エラー | エラーハンドリング不足 | try-exceptブロックを追加 |
| パフォーマンス問題 | 最適化不足 | プロファイリングと最適化 |

### 7.2 プロンプト改善のヒント

- **エラーが発生した場合**: エラーメッセージをプロンプトに含める
- **期待と異なる出力**: より具体的な例を追加
- **コード品質が低い**: コード規約やベストプラクティスを明示

---

## 8. 付録

### 8.1 プロンプトテンプレート一覧

- F001: ステート管理機能
- F002: Supervisorノード機能
- F003: Researcherノード機能
- F004: Writerノード機能
- F005: Reviewerノード機能
- F006: グラフ構築・ルーティング機能
- F007: 検索ツール機能
- F008: スクレイピングツール機能
- F009: チェックポイント機能
- F010: Human-in-the-Loop機能
- F011: エラーハンドリング機能
- F012: ロギング・可観測性機能
- データモデル（Pydantic）
- 設定管理
- プロンプトテンプレートファイル

### 8.2 参考資料

- LangGraph Documentation
- LangChain 1.0 Migration Guide
- Pydantic Documentation
- Python Type Hints Guide

---

## 9. 変更履歴

| バージョン | 日付 | 変更内容 |
|-----------|------|---------|
| 1.0 | 2024-12-27 | 初版作成 |
| 1.1 | 2025-02-01 | ドキュメント情報・変更履歴更新 |

