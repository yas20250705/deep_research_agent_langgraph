# 詳細設計書：LangGraph搭載 自律型リサーチエージェント

## 1. ドキュメント情報

- **文書名**: 詳細設計書（機能単位の仕様）
- **バージョン**: 1.0
- **作成日**: 2024-12-27
- **対象システム**: LangGraph搭載 自律型リサーチエージェント
- **参照文書**: 要求定義書、基本設計書

---

## 2. 機能一覧

| 機能ID | 機能名 | 概要 | 優先度 |
|--------|--------|------|--------|
| F001 | ステート管理機能 | グラフ全体で共有する状態の管理 | 高 |
| F002 | Supervisorノード機能 | 計画立案とルーティング決定 | 高 |
| F003 | Researcherノード機能 | Web検索と情報収集 | 高 |
| F004 | Writerノード機能 | レポートドラフト作成 | 高 |
| F005 | Reviewerノード機能 | ドラフト評価とフィードバック | 高 |
| F006 | グラフ構築・ルーティング機能 | LangGraphの構築と条件分岐 | 高 |
| F007 | 検索ツール機能 | Tavily API連携 | 高 |
| F008 | スクレイピングツール機能 | Webページコンテンツ取得 | 中 |
| F009 | チェックポイント機能 | 状態の永続化と復元 | 中 |
| F010 | Human-in-the-Loop機能 | 人間介入ポイントの実装 | 中 |
| F011 | エラーハンドリング機能 | エラー処理とリトライ | 高 |
| F012 | ロギング・可観測性機能 | 実行ログとトレーシング | 中 |

---

## 3. 機能詳細仕様

### 3.1 F001: ステート管理機能

#### 3.1.1 機能概要

LangGraphの共有ステートを管理する機能。全ノードが参照・更新するデータ構造を定義し、型安全性を保証する。

#### 3.1.2 入力仕様

- **初期ステート**: ユーザー入力から生成される初期状態
- **ノードからの更新**: 各ノードが実行時にステートを更新

#### 3.1.3 出力仕様

- **更新されたステート**: 各ノードが更新した状態を次のノードに渡す

#### 3.1.4 データ構造詳細

**ファイル**: `src/graph/state.py`

```python
from typing import TypedDict, List, Optional, Literal, Annotated
from langchain_core.messages import BaseMessage, HumanMessage, AIMessage
from langgraph.graph.message import add_messages
from src.schemas.data_models import ResearchPlan, SearchResult

class ResearchState(TypedDict):
    """
    リサーチエージェントの共有ステート
    
    各フィールドの説明:
    - messages: LangGraph標準のメッセージ履歴（自動マージ）
    - task_plan: 調査計画（初回Supervisor実行時に生成）
    - research_data: 収集された検索結果のリスト
    - current_draft: Writerが生成したレポートドラフト
    - feedback: Reviewerからの改善フィードバック
    - iteration_count: ループ回数（無限ループ防止）
    - next_action: 次のアクション（ルーティング用）
    - human_input_required: 人間介入が必要かどうか
    - human_input: 人間からの入力内容
    """
    
    # メッセージ履歴（LangGraph標準、自動マージ）
    messages: Annotated[
        List[BaseMessage], 
        add_messages
    ]
    
    # 調査計画（初回はNone、Supervisorで生成）
    task_plan: Optional[ResearchPlan]
    
    # 収集された研究データ（Researcherが追加）
    research_data: List[SearchResult]
    
    # 現在のドラフト（Writerが生成）
    current_draft: Optional[str]
    
    # Reviewerからのフィードバック
    feedback: Optional[str]
    
    # ループ回数（各ノード実行時にインクリメント）
    iteration_count: int
    
    # 次のアクション（ルーティング決定用）
    next_action: Literal["research", "write", "review", "end"]
    
    # 人間介入フラグ
    human_input_required: bool
    
    # 人間からの入力
    human_input: Optional[str]
```

#### 3.1.5 処理フロー

1. **初期化**: ユーザー入力から初期ステートを生成
2. **更新**: 各ノードがステートを更新（イミュータブルな更新）
3. **検証**: ステートの整合性をチェック
4. **永続化**: チェックポイントに保存（オプション）

#### 3.1.6 バリデーション

- `messages`: 空リストは許可、`BaseMessage`のリストであることを確認
- `task_plan`: Noneまたは有効な`ResearchPlan`オブジェクト
- `research_data`: リスト（空リスト可）、各要素は`SearchResult`
- `iteration_count`: 0以上の整数、最大値は設定で制御
- `next_action`: 指定されたリテラル値のみ許可

#### 3.1.7 エラーハンドリング

- 型不一致エラー: Pydanticバリデーションで検出
- 不正なステート遷移: カスタムバリデーターで検証

#### 3.1.8 実装上の注意点

- `messages`は`Annotated`と`add_messages`を使用して自動マージ
- ステートはイミュータブルに扱う（新しい辞書を返す）
- 型ヒントを活用してIDEの補完を有効化

---

### 3.2 F002: Supervisorノード機能

#### 3.2.1 機能概要

調査計画の立案と、次のアクション（research/write/end）の決定を行う司令塔ノード。

#### 3.2.2 入力仕様

**入力**: `ResearchState`

- `messages`: ユーザー入力または前回のメッセージ履歴
- `task_plan`: 既存の計画（初回はNone）
- `research_data`: 既に収集されたデータ
- `iteration_count`: 現在のループ回数

#### 3.2.3 出力仕様

**出力**: `ResearchState`

- `task_plan`: 生成または更新された調査計画
- `next_action`: 決定された次のアクション
- `messages`: 計画と判断理由を記録したメッセージ

#### 3.2.4 処理フロー詳細

**ファイル**: `src/nodes/supervisor.py`

```python
def supervisor_node(state: ResearchState) -> ResearchState:
    """
    Supervisorノード: 計画立案とルーティング決定
    
    処理ステップ:
    1. メッセージ履歴からユーザーのテーマを抽出
    2. task_planが未設定の場合、調査計画を生成
    3. 現在の進捗を評価（research_dataの量と質）
    4. 次のアクションを決定
    5. 判断理由をメッセージに記録
    """
    
    # ステップ1: テーマ抽出
    user_message = extract_user_message(state["messages"])
    theme = extract_theme(user_message)
    
    # ステップ2: 計画生成（未設定の場合）
    if state["task_plan"] is None:
        plan = generate_research_plan(theme, state, llm)
        state["task_plan"] = plan
    else:
        plan = state["task_plan"]
    
    # ステップ3: 進捗評価
    progress = evaluate_progress(state)
    
    # ステップ4: ルーティング決定
    next_action, reasoning = decide_next_action(
        state=state,
        progress=progress,
        llm=llm
    )
    
    # ステップ5: メッセージ記録
    state["messages"].append(
        AIMessage(content=f"次のアクション: {next_action}\n理由: {reasoning}")
    )
    
    state["next_action"] = next_action
    return state
```

#### 3.2.5 サブ関数仕様

##### 3.2.5.1 `generate_research_plan()`

**目的**: ユーザーのテーマから調査計画を生成

**入力**:
- `theme: str`: 調査テーマ
- `state: ResearchState`: 現在のステート
- `llm: ChatOpenAI`: LLMインスタンス

**出力**: `ResearchPlan`

**処理**:
1. LLMにプロンプトを送信（`SUPERVISOR_PLANNING_PROMPT`）
2. JSON形式の計画を取得
3. Pydanticモデルに変換
4. バリデーション

**プロンプトテンプレート**:
```
あなたはリサーチエージェントのSupervisorです。
以下のテーマについて、詳細な調査計画を立ててください。

テーマ: {theme}

以下のJSON形式で応答してください:
{{
    "theme": "{theme}",
    "investigation_points": ["観点1", "観点2", ...],
    "search_queries": ["クエリ1", "クエリ2", ...],
    "plan_text": "計画の説明文"
}}
```

##### 3.2.5.2 `evaluate_progress()`

**目的**: 現在の進捗状況を評価

**入力**: `ResearchState`

**出力**: `Dict[str, Any]`
- `data_count: int`: 収集データ数
- `data_quality: float`: データ品質スコア（0-1）
- `coverage: float`: 計画に対する網羅性（0-1）

**評価基準**:
- データ数: `research_data`の長さ
- データ品質: 関連性スコアの平均
- 網羅性: 計画の検索クエリに対するカバレッジ

##### 3.2.5.3 `decide_next_action()`

**目的**: 次のアクションを決定

**入力**:
- `state: ResearchState`
- `progress: Dict`
- `llm: ChatOpenAI`

**出力**: `Tuple[str, str]` (next_action, reasoning)

**決定ロジック**:

```python
def decide_next_action(state, progress, llm) -> Tuple[str, str]:
    """
    ルーティング決定ロジック
    
    1. 最大イテレーション到達 → "end"
    2. データ不足（data_count < 5） → "research"
    3. データは十分だがドラフト未作成 → "write"
    4. ドラフトあり、レビュー未実施 → "review"（実際はWriter→Reviewerのエッジで処理）
    5. その他 → LLMに判断を委譲
    """
    
    # 最大イテレーション確認
    if state["iteration_count"] >= MAX_ITERATIONS:
        return "end", "最大イテレーション数に到達しました"
    
    # データ不足
    if progress["data_count"] < MIN_RESEARCH_DATA_COUNT:
        return "research", f"データが不足しています（現在: {progress['data_count']}件）"
    
    # ドラフト未作成
    if state["current_draft"] is None and progress["data_count"] >= MIN_RESEARCH_DATA_COUNT:
        return "write", "十分なデータが集まりました。ドラフトを作成します"
    
    # LLMに判断を委譲（複雑なケース）
    return llm_based_routing(state, progress, llm)
```

#### 3.2.6 エラーハンドリング

- **LLM呼び出しエラー**: リトライ（最大3回）、失敗時はデフォルトアクション
- **JSONパースエラー**: 再生成を試行、失敗時はエラーメッセージを記録
- **計画生成エラー**: 簡易計画をフォールバックとして使用

#### 3.2.7 パフォーマンス要件

- 計画生成: 5秒以内
- ルーティング決定: 2秒以内（LLM呼び出し含む）

---

### 3.3 F003: Researcherノード機能

#### 3.3.1 機能概要

Web検索を実行し、関連情報を収集・整理するノード。

#### 3.3.2 入力仕様

**入力**: `ResearchState`

- `task_plan`: 検索クエリを含む調査計画
- `research_data`: 既存の検索結果（重複除去用）

#### 3.3.3 出力仕様

**出力**: `ResearchState`

- `research_data`: 新しい検索結果を追加したリスト
- `messages`: 検索結果のサマリーを記録

#### 3.3.4 処理フロー詳細

**ファイル**: `src/nodes/researcher.py`

```python
def researcher_node(state: ResearchState) -> ResearchState:
    """
    Researcherノード: Web検索と情報収集
    
    処理ステップ:
    1. task_planから検索クエリを取得
    2. 各クエリに対してTavily検索を実行
    3. 検索結果をSearchResultモデルに変換
    4. 重複除去（URLベース）
    5. research_dataに追加
    6. メッセージに結果を記録
    """
    
    plan = state["task_plan"]
    if plan is None:
        raise ValueError("task_plan is required")
    
    # 既存URLのセット（重複除去用）
    existing_urls = {r.url for r in state["research_data"]}
    
    new_results = []
    
    # 各検索クエリを実行
    for query in plan.search_queries:
        try:
            # Tavily検索実行
            search_results = tavily_search_tool.invoke({
                "query": query,
                "max_results": MAX_RESULTS_PER_QUERY
            })
            
            # SearchResultに変換
            for result in search_results:
                search_result = SearchResult(
                    title=result.get("title", ""),
                    summary=result.get("content", "")[:500],  # 要約を500文字に制限
                    url=result.get("url", ""),
                    source="tavily",
                    published_date=result.get("published_date"),
                    relevance_score=result.get("score", 0.0)
                )
                
                # 重複チェック
                if search_result.url not in existing_urls:
                    new_results.append(search_result)
                    existing_urls.add(search_result.url)
        
        except Exception as e:
            logger.error(f"Search error for query '{query}': {e}")
            # エラーを記録し、次のクエリに進む
            state["messages"].append(
                AIMessage(content=f"検索エラー（クエリ: {query}）: {str(e)}")
            )
    
    # 結果を追加
    state["research_data"].extend(new_results)
    state["iteration_count"] += 1
    
    # サマリーメッセージ
    summary = f"検索完了: {len(new_results)}件の新しい結果を追加しました（合計: {len(state['research_data'])}件）"
    state["messages"].append(AIMessage(content=summary))
    
    return state
```

#### 3.3.5 検索クエリ最適化

**ファイル**: `src/nodes/researcher.py` (補助関数)

```python
def optimize_search_queries(
    base_queries: List[str],
    feedback: Optional[str]
) -> List[str]:
    """
    フィードバックに基づいて検索クエリを最適化
    
    例:
    - フィードバック: "最新の情報が不足"
    → クエリに "2024" や "最新" を追加
    """
    if feedback is None:
        return base_queries
    
    # LLMを使用してクエリを改善
    optimized = llm_optimize_queries(base_queries, feedback)
    return optimized
```

#### 3.3.6 エラーハンドリング

- **API呼び出しエラー**: リトライ（指数バックオフ）、最大3回
- **タイムアウト**: 10秒でタイムアウト、エラーを記録
- **無効なURL**: URL検証を実施、無効なものはスキップ
- **空の結果**: 警告を記録、処理は継続

#### 3.3.7 パフォーマンス要件

- 1クエリあたり: 3秒以内
- 並列検索: 最大5クエリを同時実行（オプション）

---

### 3.4 F004: Writerノード機能

#### 3.4.1 機能概要

収集された情報を統合し、マークダウンレポートのドラフトを作成するノード。

#### 3.4.2 入力仕様

**入力**: `ResearchState`

- `research_data`: 収集された検索結果
- `task_plan`: 調査テーマと計画
- `feedback`: 前回のレビューフィードバック（再執筆時）

#### 3.4.3 出力仕様

**出力**: `ResearchState`

- `current_draft`: 生成されたマークダウンレポート
- `messages`: ドラフト生成完了メッセージ

#### 3.4.4 処理フロー詳細

**ファイル**: `src/nodes/writer.py`

```python
def writer_node(state: ResearchState) -> ResearchState:
    """
    Writerノード: レポートドラフト作成
    
    処理ステップ:
    1. research_dataを構造化テキストに変換
    2. フィードバックがある場合は考慮
    3. LLMにレポート生成を依頼
    4. マークダウン形式で出力
    5. current_draftに保存
    """
    
    plan = state["task_plan"]
    if plan is None:
        raise ValueError("task_plan is required")
    
    # 研究データをテキストに変換
    research_text = format_research_data(state["research_data"])
    
    # フィードバックの考慮
    feedback_context = ""
    if state["feedback"]:
        feedback_context = f"\n\n前回のフィードバック:\n{state['feedback']}\n\nこのフィードバックを反映してください。"
    
    # プロンプト構築
    prompt = ChatPromptTemplate.from_messages([
        ("system", WRITER_SYSTEM_PROMPT),
        ("human", WRITER_USER_PROMPT.format(
            theme=plan.theme,
            investigation_points="\n".join(f"- {p}" for p in plan.investigation_points),
            research_data=research_text,
            feedback=feedback_context
        ))
    ])
    
    # LLM呼び出し
    chain = prompt | llm
    response = chain.invoke({})
    
    # ドラフトを保存
    draft = extract_markdown_content(response.content)
    state["current_draft"] = draft
    state["iteration_count"] += 1
    
    # メッセージ記録
    state["messages"].append(
        AIMessage(content=f"ドラフトを生成しました（長さ: {len(draft)}文字）")
    )
    
    return state
```

#### 3.4.5 サブ関数仕様

##### 3.4.5.1 `format_research_data()`

**目的**: 検索結果を構造化テキストに変換

**入力**: `List[SearchResult]`

**出力**: `str`

**フォーマット例**:
```
[ソース1]
タイトル: {title}
URL: {url}
要約: {summary}
関連性スコア: {relevance_score}

[ソース2]
...
```

##### 3.4.5.2 `extract_markdown_content()`

**目的**: LLMの応答からマークダウンコンテンツを抽出

**入力**: `str` (LLM応答)

**出力**: `str` (マークダウンのみ)

**処理**: コードブロックや余分なテキストを除去

#### 3.4.6 プロンプト仕様

**システムプロンプト**: `src/prompts/writer_prompt.py`

```
あなたは専門的なリサーチレポートを執筆するWriterです。

要件:
1. エグゼクティブサマリー（200-300文字）を含める
2. 主要な発見を3-5個の箇条書きで列挙
3. 詳細な分析を提供（各観点について説明）
4. すべての主張に出典URLを明記 [^1]
5. マークダウン形式で出力

構造:
# {テーマ}

## Executive Summary
{サマリー}

## Key Findings
{箇条書き}

## Detailed Analysis
{詳細分析}

## References
[^1]: {URL1}
[^2]: {URL2}
...
```

#### 3.4.7 エラーハンドリング

- **LLM呼び出しエラー**: リトライ、失敗時は簡易ドラフトを生成
- **マークダウン解析エラー**: プレーンテキストとして保存
- **データ不足**: 警告を記録、可能な範囲でドラフト生成

#### 3.4.8 パフォーマンス要件

- ドラフト生成: 30秒以内（研究データ10件の場合）

---

### 3.5 F005: Reviewerノード機能

#### 3.5.1 機能概要

ドラフトの品質を評価し、改善フィードバックを生成するノード。

#### 3.5.2 入力仕様

**入力**: `ResearchState`

- `current_draft`: 評価対象のドラフト
- `research_data`: ファクトチェック用のソースデータ
- `task_plan`: 計画との整合性確認用

#### 3.5.3 出力仕様

**出力**: `ResearchState`

- `feedback`: 改善フィードバック（不合格の場合）
- `next_action`: 次のアクション（"research", "write", "end"）
- `messages`: 評価結果の記録

#### 3.5.4 処理フロー詳細

**ファイル**: `src/nodes/reviewer.py`

```python
def reviewer_node(state: ResearchState) -> ResearchState:
    """
    Reviewerノード: ドラフト評価とフィードバック
    
    処理ステップ:
    1. ドラフトの存在確認
    2. ファクトチェック（出典との整合性）
    3. 網羅性チェック（計画との整合性）
    4. 論理的一貫性チェック
    5. 総合評価とフィードバック生成
    6. 次のアクション決定
    """
    
    draft = state["current_draft"]
    if draft is None:
        raise ValueError("current_draft is required")
    
    # 評価プロンプト構築
    evaluation = evaluate_draft(
        draft=draft,
        research_data=state["research_data"],
        task_plan=state["task_plan"],
        llm=llm
    )
    
    # 評価結果をパース
    eval_result = parse_evaluation_result(evaluation)
    
    # 次のアクション決定
    if eval_result["approved"]:
        state["next_action"] = "end"
        state["feedback"] = None
        state["messages"].append(
            AIMessage(content="レビュー完了: ドラフトは承認されました")
        )
    else:
        state["next_action"] = eval_result["suggested_action"]
        state["feedback"] = eval_result["feedback"]
        state["messages"].append(
            AIMessage(content=f"レビュー結果: 改善が必要\nフィードバック: {eval_result['feedback']}")
        )
    
    state["iteration_count"] += 1
    return state
```

#### 3.5.5 評価基準

**評価観点**:

1. **ファクトチェック** (重み: 40%)
   - ドラフトの主張が`research_data`のソースと一致しているか
   - 出典URLが正しく記載されているか
   - 幻覚（hallucination）がないか

2. **網羅性** (重み: 30%)
   - `task_plan`の調査観点がすべてカバーされているか
   - 主要な検索結果が反映されているか

3. **論理的一貫性** (重み: 20%)
   - 論理的な流れがあるか
   - 矛盾がないか

4. **形式・構造** (重み: 10%)
   - マークダウン形式が正しいか
   - 必要なセクションが含まれているか

**合格基準**: 総合スコア >= 0.8 かつ ファクトチェックスコア >= 0.9

#### 3.5.6 評価結果フォーマット

**JSON形式**:

```json
{
    "approved": false,
    "overall_score": 0.75,
    "scores": {
        "fact_check": 0.9,
        "completeness": 0.7,
        "logic": 0.8,
        "format": 0.6
    },
    "feedback": "詳細な分析セクションで、観点3についての説明が不足しています。また、参考文献の形式を統一してください。",
    "suggested_action": "write",
    "issues": [
        {
            "type": "completeness",
            "severity": "medium",
            "description": "観点3の説明が不足",
            "location": "Detailed Analysisセクション"
        },
        {
            "type": "format",
            "severity": "low",
            "description": "参考文献の形式が統一されていない",
            "location": "Referencesセクション"
        }
    ]
}
```

#### 3.5.7 エラーハンドリング

- **ドラフト未設定**: エラーを発生、前のノードに戻る
- **評価パースエラー**: 再評価を試行、失敗時はデフォルト評価
- **LLM呼び出しエラー**: リトライ、失敗時は簡易評価を実行

---

### 3.6 F006: グラフ構築・ルーティング機能

#### 3.6.1 機能概要

LangGraphのグラフを構築し、条件分岐によるルーティングを実装する機能。

#### 3.6.2 入力仕様

**入力**: なし（設定とノード関数を受け取る）

#### 3.6.3 出力仕様

**出力**: `CompiledGraph` (LangGraphのコンパイル済みグラフ)

#### 3.6.4 処理フロー詳細

**ファイル**: `src/graph/graph_builder.py`

```python
from langgraph.graph import StateGraph, END
from src.graph.state import ResearchState
from src.nodes.supervisor import supervisor_node
from src.nodes.researcher import researcher_node
from src.nodes.writer import writer_node
from src.nodes.reviewer import reviewer_node
from src.graph.edges import route_supervisor, route_reviewer

def build_graph(
    checkpointer=None,
    interrupt_before: Optional[List[str]] = None
) -> CompiledGraph:
    """
    グラフを構築してコンパイル
    
    グラフ構造:
    START → supervisor → [conditional] → researcher/writer/end
                                    ↓
                              researcher → supervisor
                                    ↓
                              writer → reviewer
                                    ↓
                              reviewer → [conditional] → researcher/writer/end
    """
    
    # グラフ作成
    graph = StateGraph(ResearchState)
    
    # ノード追加
    graph.add_node("supervisor", supervisor_node)
    graph.add_node("researcher", researcher_node)
    graph.add_node("writer", writer_node)
    graph.add_node("reviewer", reviewer_node)
    
    # エントリーポイント
    graph.set_entry_point("supervisor")
    
    # Supervisorからの条件分岐
    graph.add_conditional_edges(
        "supervisor",
        route_supervisor,
        {
            "research": "researcher",
            "write": "writer",
            "end": END
        }
    )
    
    # Researcher → Supervisor（常に）
    graph.add_edge("researcher", "supervisor")
    
    # Writer → Reviewer（常に）
    graph.add_edge("writer", "reviewer")
    
    # Reviewerからの条件分岐
    graph.add_conditional_edges(
        "reviewer",
        route_reviewer,
        {
            "research": "researcher",
            "write": "writer",
            "end": END
        }
    )
    
    # コンパイル
    compiled = graph.compile(
        checkpointer=checkpointer,
        interrupt_before=interrupt_before or []
    )
    
    return compiled
```

#### 3.6.5 ルーティング関数仕様

**ファイル**: `src/graph/edges.py`

```python
def route_supervisor(state: ResearchState) -> str:
    """
    Supervisorからのルーティング
    
    単純にnext_actionを返す
    """
    return state["next_action"]

def route_reviewer(state: ResearchState) -> str:
    """
    Reviewerからのルーティング
    
    最大イテレーション確認を含む
    """
    # 最大イテレーション確認
    if state["iteration_count"] >= MAX_ITERATIONS:
        logger.warning(f"Max iterations reached: {state['iteration_count']}")
        return "end"
    
    return state["next_action"]
```

#### 3.6.6 Human-in-the-Loop実装

```python
# 人間介入ポイントを設定
compiled_graph = build_graph(
    checkpointer=checkpointer,
    interrupt_before=["supervisor", "writer"]  # これらのノード前に中断
)

# 実行（中断時は待機）
config = {"configurable": {"thread_id": "thread-1"}}
result = compiled_graph.invoke(initial_state, config)

# 中断された場合、状態を確認
state = compiled_graph.get_state(config)
if state.next:
    # 人間入力待ち
    human_input = get_human_input()
    
    # 状態を更新
    compiled_graph.update_state(
        config,
        {"human_input": human_input}
    )
    
    # 再開
    result = compiled_graph.invoke(None, config)
```

---

### 3.7 F007: 検索ツール機能

#### 3.7.1 機能概要

Tavily Search APIを使用してWeb検索を実行するツール。

#### 3.7.2 入力仕様

**入力**:
- `query: str`: 検索クエリ（必須）
- `max_results: int`: 最大結果数（デフォルト: 5）

#### 3.7.3 出力仕様

**出力**: `List[Dict[str, Any]]`

各要素の構造:
```python
{
    "title": str,           # ページタイトル
    "url": str,             # URL
    "content": str,         # コンテンツ要約
    "score": float,         # 関連性スコア（0-1）
    "published_date": str   # 公開日（オプション）
}
```

#### 3.7.4 処理フロー詳細

**ファイル**: `src/tools/search_tool.py`

```python
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.tools import tool
from tenacity import retry, stop_after_attempt, wait_exponential
import os

@tool
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10)
)
def tavily_search_tool(query: str, max_results: int = 5) -> List[Dict[str, Any]]:
    """
    Tavily Search APIを使用してWeb検索を実行
    
    Args:
        query: 検索クエリ
        max_results: 最大結果数（1-10推奨）
    
    Returns:
        検索結果のリスト
    
    Raises:
        ValueError: クエリが空の場合
        APIError: Tavily API呼び出しエラー
    """
    
    if not query or not query.strip():
        raise ValueError("検索クエリが空です")
    
    if max_results < 1 or max_results > 20:
        raise ValueError("max_resultsは1-20の範囲で指定してください")
    
    # Tavilyツール初期化
    tavily = TavilySearchResults(
        max_results=max_results,
        api_key=os.getenv("TAVILY_API_KEY")
    )
    
    # 検索実行
    try:
        results = tavily.invoke({"query": query})
        return results
    except Exception as e:
        logger.error(f"Tavily search error: {e}")
        raise
```

#### 3.7.5 エラーハンドリング

- **APIキー未設定**: `ValueError`を発生
- **ネットワークエラー**: リトライ（指数バックオフ）
- **タイムアウト**: 10秒でタイムアウト
- **無効なレスポンス**: エラーログを記録、空リストを返す

#### 3.7.6 パフォーマンス要件

- 1回の検索: 3秒以内
- タイムアウト: 10秒

---

### 3.8 F008: スクレイピングツール機能

#### 3.8.1 機能概要

指定URLのWebページからテキストコンテンツを抽出するツール。

#### 3.8.2 入力仕様

**入力**:
- `url: str`: スクレイピング対象URL（必須）

#### 3.8.3 出力仕様

**出力**: `str` (ページのテキストコンテンツ)

#### 3.8.4 処理フロー詳細

**ファイル**: `src/tools/scraper_tool.py`

```python
from langchain_core.tools import tool
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import re

@tool
def web_scraper_tool(url: str) -> str:
    """
    指定URLのコンテンツをスクレイピング
    
    Args:
        url: スクレイピング対象URL
    
    Returns:
        ページのテキストコンテンツ
    
    Raises:
        ValueError: URLが無効な場合
        RequestException: HTTPリクエストエラー
    """
    
    # URL検証
    if not is_valid_url(url):
        raise ValueError(f"無効なURL: {url}")
    
    # リクエスト実行
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Research Agent Bot)"
        }
        response = requests.get(url, timeout=10, headers=headers)
        response.raise_for_status()
    except requests.RequestException as e:
        logger.error(f"Request error for {url}: {e}")
        raise
    
    # HTMLパース
    soup = BeautifulSoup(response.content, "html.parser")
    
    # メインコンテンツ抽出
    content = extract_main_content(soup)
    
    # テキストクリーンアップ
    cleaned = clean_text(content)
    
    return cleaned

def extract_main_content(soup: BeautifulSoup) -> str:
    """
    メインコンテンツを抽出
    
    優先順位:
    1. <main>タグ
    2. <article>タグ
    3. <div class="content">等
    4. <body>タグ（フォールバック）
    """
    # mainタグ
    main = soup.find("main")
    if main:
        return main.get_text()
    
    # articleタグ
    article = soup.find("article")
    if article:
        return article.get_text()
    
    # コンテンツクラス
    content_div = soup.find("div", class_=re.compile("content|main|article"))
    if content_div:
        return content_div.get_text()
    
    # フォールバック: body
    body = soup.find("body")
    if body:
        # スクリプトとスタイルを除去
        for script in body(["script", "style"]):
            script.decompose()
        return body.get_text()
    
    return ""

def clean_text(text: str) -> str:
    """
    テキストをクリーンアップ
    - 余分な空白を除去
    - 改行を正規化
    """
    # 複数の空白を1つに
    text = re.sub(r'\s+', ' ', text)
    # 改行を正規化
    text = re.sub(r'\n\s*\n', '\n\n', text)
    return text.strip()
```

#### 3.8.5 エラーハンドリング

- **無効なURL**: `ValueError`を発生
- **HTTPエラー**: エラーログを記録、空文字列を返す
- **タイムアウト**: 10秒でタイムアウト
- **パースエラー**: フォールバック処理

---

### 3.9 F009: チェックポイント機能

#### 3.9.1 機能概要

グラフの実行状態を永続化し、後から復元できるようにする機能。

#### 3.9.2 入力仕様

**入力**: 
- `checkpointer_type: str`: "memory" または "redis"
- `redis_config: Optional[Dict]`: Redis設定（redis使用時）

#### 3.9.3 出力仕様

**出力**: `Checkpointer` インスタンス

#### 3.9.4 処理フロー詳細

**ファイル**: `src/utils/checkpointer.py`

```python
from langgraph.checkpoint.memory import MemorySaver
from langgraph.checkpoint.redis import RedisCheckpointer
import redis
from src.config.settings import Settings

def create_checkpointer(
    checkpointer_type: str = "memory",
    redis_config: Optional[Dict] = None
) -> Checkpointer:
    """
    チェックポインターを作成
    
    Args:
        checkpointer_type: "memory" または "redis"
        redis_config: Redis設定（redis使用時）
    
    Returns:
        Checkpointerインスタンス
    """
    
    if checkpointer_type == "memory":
        return MemorySaver()
    
    elif checkpointer_type == "redis":
        if redis_config is None:
            settings = Settings()
            redis_config = {
                "host": settings.REDIS_HOST,
                "port": settings.REDIS_PORT,
                "db": settings.REDIS_DB
            }
        
        redis_client = redis.Redis(**redis_config)
        return RedisCheckpointer(redis_client)
    
    else:
        raise ValueError(f"Unknown checkpointer type: {checkpointer_type}")

def save_checkpoint(
    graph: CompiledGraph,
    config: Dict,
    state: ResearchState
) -> None:
    """
    チェックポイントを保存（明示的）
    
    通常はLangGraphが自動的に保存するが、
    重要なポイントで明示的に保存することも可能
    """
    graph.update_state(config, state)

def load_checkpoint(
    graph: CompiledGraph,
    config: Dict
) -> Optional[ResearchState]:
    """
    チェックポイントから状態を復元
    """
    state = graph.get_state(config)
    if state.values:
        return state.values
    return None
```

#### 3.9.5 使用例

```python
# チェックポイント作成
checkpointer = create_checkpointer("redis")

# グラフに設定
graph = build_graph(checkpointer=checkpointer)

# 実行（自動保存）
config = {"configurable": {"thread_id": "session-123"}}
result = graph.invoke(initial_state, config)

# 後で復元
state = load_checkpoint(graph, config)
```

---

### 3.10 F010: Human-in-the-Loop機能

#### 3.10.1 機能概要

グラフ実行中に人間の承認や入力を受け付ける機能。

#### 3.10.2 入力仕様

**入力**:
- `interrupt_before: List[str]`: 中断するノード名のリスト
- `human_input: str`: 人間からの入力

#### 3.10.3 出力仕様

**出力**: 更新されたステート

#### 3.10.4 処理フロー詳細

**ファイル**: `src/utils/human_in_loop.py`

```python
def setup_human_intervention(
    graph: CompiledGraph,
    interrupt_nodes: List[str]
) -> CompiledGraph:
    """
    人間介入ポイントを設定
    
    Args:
        graph: コンパイル済みグラフ
        interrupt_nodes: 中断するノード名のリスト
    
    Returns:
        設定済みグラフ
    """
    # interrupt_beforeは既にgraph_builderで設定済み
    # この関数は補助的な処理を行う
    return graph

def wait_for_human_input(
    graph: CompiledGraph,
    config: Dict
) -> Optional[str]:
    """
    人間入力を待つ
    
    Returns:
        人間からの入力文字列、またはNone（タイムアウト）
    """
    state = graph.get_state(config)
    
    if state.next:
        # 中断されている
        # 実際の実装では、UIやAPI経由で入力を受け取る
        human_input = input("入力してください: ")
        return human_input
    
    return None

def resume_with_input(
    graph: CompiledGraph,
    config: Dict,
    human_input: str
) -> ResearchState:
    """
    人間入力でグラフを再開
    
    Args:
        graph: コンパイル済みグラフ
        config: 設定
        human_input: 人間からの入力
    
    Returns:
        更新されたステート
    """
    # ステートを更新
    graph.update_state(config, {"human_input": human_input})
    
    # 再開
    result = graph.invoke(None, config)
    return result
```

#### 3.10.5 使用例

```python
# 人間介入ポイントを設定
graph = build_graph(
    interrupt_before=["supervisor", "writer"]
)

# 実行（中断される可能性がある）
config = {"configurable": {"thread_id": "thread-1"}}
result = graph.invoke(initial_state, config)

# 中断されているか確認
state = graph.get_state(config)
if state.next:
    # 人間入力を取得
    human_input = wait_for_human_input(graph, config)
    
    # 再開
    result = resume_with_input(graph, config, human_input)
```

---

### 3.11 F011: エラーハンドリング機能

#### 3.11.1 機能概要

システム全体のエラー処理とリトライロジックを実装する機能。

#### 3.11.2 エラータイプ

| エラータイプ | 説明 | 処理方法 |
|-------------|------|----------|
| LLM呼び出しエラー | OpenAI APIエラー | リトライ（指数バックオフ） |
| 検索APIエラー | Tavily APIエラー | リトライ、フォールバック |
| ネットワークエラー | タイムアウト等 | リトライ、エラー記録 |
| バリデーションエラー | データ形式エラー | エラーメッセージ、前のステップに戻る |
| 最大イテレーション | ループ回数超過 | 強制終了 |

#### 3.11.3 リトライ戦略

**ファイル**: `src/utils/retry.py`

```python
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)
import openai
import requests

# LLM呼び出し用リトライ
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    retry=retry_if_exception_type(openai.APIError)
)
def call_llm_with_retry(llm, prompt):
    """LLM呼び出し（リトライ付き）"""
    return llm.invoke(prompt)

# 検索API用リトライ
@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=2, max=8),
    retry=retry_if_exception_type(requests.RequestException)
)
def search_with_retry(tool, query):
    """検索実行（リトライ付き）"""
    return tool.invoke({"query": query})
```

#### 3.11.4 エラーハンドリングデコレータ

**ファイル**: `src/utils/error_handler.py`

```python
from functools import wraps
import logging

logger = logging.getLogger(__name__)

def handle_node_errors(node_func):
    """
    ノード実行時のエラーをハンドルするデコレータ
    """
    @wraps(node_func)
    def wrapper(state: ResearchState) -> ResearchState:
        try:
            return node_func(state)
        except Exception as e:
            logger.error(f"Error in {node_func.__name__}: {e}", exc_info=True)
            
            # エラーをステートに記録
            state["messages"].append(
                AIMessage(content=f"エラーが発生しました: {str(e)}")
            )
            
            # 次のアクションを終了に設定
            state["next_action"] = "end"
            
            return state
    
    return wrapper
```

---

### 3.12 F012: ロギング・可観測性機能

#### 3.12.1 機能概要

システムの実行ログとトレーシング情報を記録する機能。

#### 3.12.2 ログレベル

- **DEBUG**: 詳細なデバッグ情報
- **INFO**: 一般的な情報（ノード実行開始/終了等）
- **WARNING**: 警告（最大イテレーション接近等）
- **ERROR**: エラー（API呼び出し失敗等）

#### 3.12.3 ログ出力項目

**ファイル**: `src/utils/logger.py`

```python
import logging
from datetime import datetime
from typing import Dict, Any

def setup_logger(name: str = "research_agent") -> logging.Logger:
    """
    ロガーを設定
    
    Returns:
        設定済みロガー
    """
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    # ハンドラー設定
    handler = logging.StreamHandler()
    formatter = logging.Formatter(
        '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    handler.setFormatter(formatter)
    logger.addHandler(handler)
    
    return logger

def log_node_execution(
    logger: logging.Logger,
    node_name: str,
    state: ResearchState,
    duration: float
):
    """
    ノード実行をログに記録
    
    Args:
        logger: ロガー
        node_name: ノード名
        state: ステート
        duration: 実行時間（秒）
    """
    logger.info(
        f"Node: {node_name} | "
        f"Iteration: {state['iteration_count']} | "
        f"Next Action: {state['next_action']} | "
        f"Duration: {duration:.2f}s"
    )

def log_llm_call(
    logger: logging.Logger,
    prompt: str,
    response: str,
    tokens_used: int
):
    """
    LLM呼び出しをログに記録
    """
    logger.debug(
        f"LLM Call | Tokens: {tokens_used} | "
        f"Prompt Length: {len(prompt)} | "
        f"Response Length: {len(response)}"
    )
```

#### 3.12.4 LangSmith連携（オプション）

```python
import os
from langchain_core.tracers import LangChainTracer

def setup_langsmith():
    """
    LangSmithのトレーシングを設定
    """
    os.environ["LANGCHAIN_TRACING_V2"] = "true"
    os.environ["LANGCHAIN_ENDPOINT"] = "https://api.smith.langchain.com"
    os.environ["LANGCHAIN_API_KEY"] = os.getenv("LANGCHAIN_API_KEY")
    os.environ["LANGCHAIN_PROJECT"] = "research-agent"
```

---

## 4. インターフェース仕様

### 4.1 公開API

#### 4.1.1 `ResearchAgent`クラス

**ファイル**: `src/agent.py`

```python
class ResearchAgent:
    """
    リサーチエージェントのメインクラス
    
    使用例:
        agent = ResearchAgent()
        result = agent.research("LangGraphについて調査してください")
    """
    
    def __init__(
        self,
        checkpointer_type: str = "memory",
        max_iterations: int = 5,
        enable_human_intervention: bool = False
    ):
        """
        初期化
        
        Args:
            checkpointer_type: チェックポイントタイプ
            max_iterations: 最大イテレーション数
            enable_human_intervention: 人間介入を有効化
        """
        self.graph = build_graph(
            checkpointer=create_checkpointer(checkpointer_type),
            interrupt_before=["supervisor", "writer"] if enable_human_intervention else None
        )
        self.max_iterations = max_iterations
    
    def research(
        self,
        theme: str,
        thread_id: Optional[str] = None
    ) -> Dict[str, Any]:
        """
        リサーチを実行
        
        Args:
            theme: 調査テーマ
            thread_id: スレッドID（チェックポイント用）
        
        Returns:
            結果辞書（draft, sources等）
        """
        # 初期ステート作成
        initial_state = create_initial_state(theme)
        
        # 設定
        config = {
            "configurable": {
                "thread_id": thread_id or f"thread-{datetime.now().isoformat()}"
            }
        }
        
        # 実行
        result = self.graph.invoke(initial_state, config)
        
        # 結果を整形
        return {
            "draft": result["current_draft"],
            "sources": [r.dict() for r in result["research_data"]],
            "plan": result["task_plan"].dict() if result["task_plan"] else None,
            "iterations": result["iteration_count"]
        }
```

### 4.2 データモデルインターフェース

#### 4.2.1 `ResearchPlan`

```python
class ResearchPlan(BaseModel):
    theme: str
    investigation_points: List[str]
    search_queries: List[str]
    plan_text: str
    created_at: datetime
```

#### 4.2.2 `SearchResult`

```python
class SearchResult(BaseModel):
    title: str
    summary: str
    url: str
    source: str = "tavily"
    published_date: Optional[str] = None
    relevance_score: Optional[float] = None
```

---

## 5. 非機能要件の詳細

### 5.1 パフォーマンス要件

| 処理 | 目標時間 | 最大時間 |
|------|---------|---------|
| Supervisor実行 | 5秒 | 10秒 |
| Researcher実行（1クエリ） | 3秒 | 5秒 |
| Writer実行 | 30秒 | 60秒 |
| Reviewer実行 | 10秒 | 20秒 |
| 全体実行（5イテレーション） | 2分 | 5分 |

### 5.2 信頼性要件

- **可用性**: 99%以上（API障害時を除く）
- **エラー率**: 5%以下
- **データ損失**: 0%（チェックポイント使用時）

### 5.3 セキュリティ要件

- APIキーは環境変数で管理
- ユーザー入力のサニタイゼーション
- URL検証（スクレイピング前）

---

## 6. テスト仕様

### 6.1 ユニットテスト

各ノード関数の個別テスト:

```python
def test_supervisor_node():
    """Supervisorノードのテスト"""
    state = create_test_state()
    result = supervisor_node(state)
    assert result["next_action"] in ["research", "write", "end"]
    assert result["task_plan"] is not None
```

### 6.2 統合テスト

グラフ全体の実行フロー:

```python
def test_full_research_flow():
    """完全なリサーチフローのテスト"""
    agent = ResearchAgent()
    result = agent.research("テストテーマ")
    assert result["draft"] is not None
    assert len(result["sources"]) > 0
```

### 6.3 エンドツーエンドテスト

実際のテーマでのレポート生成と品質評価。

---

## 7. 実装上の制約事項

1. **LangChain 1.0以上必須**: 古いバージョンとの互換性なし
2. **Python 3.10以上**: 型ヒント機能を活用
3. **APIキー必須**: OpenAIとTavilyのAPIキーが必要
4. **メモリ使用量**: チェックポイント使用時は増加

---

## 8. 変更履歴

| バージョン | 日付 | 変更内容 |
|-----------|------|---------|
| 1.0 | 2024-12-27 | 初版作成 |

---

## 付録A: 用語集

- **StateGraph**: LangGraphのグラフ構造
- **TypedDict**: Pythonの型ヒント
- **Checkpointer**: 状態の永続化機能
- **Human-in-the-Loop**: 人間介入機能
- **Conditional Edges**: 条件分岐エッジ

## 付録B: 参考資料

- LangGraph Documentation
- LangChain 1.0 Migration Guide
- Tavily API Documentation

