"""
APIä½¿ç”¨ä¾‹: LangGraphæ­è¼‰ è‡ªå¾‹å‹ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - Streamlitãƒãƒ£ãƒƒãƒˆGUI

FastAPIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨ã—ãŸãƒªã‚µãƒ¼ãƒã®å®Ÿè¡Œä¾‹ï¼ˆãƒãƒ£ãƒƒãƒˆUIä»˜ãï¼‰
"""

import os
import sys
import time
import json
import requests
import uuid
import base64
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime
from dotenv import load_dotenv
import streamlit as st
from io import BytesIO
import re

# Webã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°ç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from bs4 import BeautifulSoup
    SCRAPING_AVAILABLE = True
except ImportError:
    SCRAPING_AVAILABLE = False

# è¨˜äº‹æŠ½å‡ºç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import trafilatura
    TRAFILATURA_AVAILABLE = True
except ImportError:
    TRAFILATURA_AVAILABLE = False

# PDFãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import PyPDF2
    PDF_TEXT_EXTRACTION_AVAILABLE = True
except ImportError:
    PDF_TEXT_EXTRACTION_AVAILABLE = False

# PDFç”Ÿæˆç”¨ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    from reportlab.lib.pagesizes import A4
    from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
    from reportlab.lib.units import mm
    from reportlab.platypus import SimpleDocTemplate, Paragraph, Spacer, PageBreak
    from reportlab.lib.enums import TA_LEFT, TA_JUSTIFY
    from reportlab.pdfbase import pdfmetrics
    from reportlab.pdfbase.ttfonts import TTFont
    from reportlab.pdfbase.cidfonts import UnicodeCIDFont
    PDF_AVAILABLE = True
except ImportError:
    PDF_AVAILABLE = False
    if 'st' in globals():
        st.warning("PDFç”Ÿæˆæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯reportlabã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: pip install reportlab")

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’ãƒ‘ã‚¹ã«è¿½åŠ ï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆã®å‰ã«å®Ÿè¡Œï¼‰
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹é–¢é€£ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆãƒ‘ã‚¹è¿½åŠ å¾Œã«å®Ÿè¡Œï¼‰
DB_AVAILABLE = False
try:
    from src.db import (
        init_db,
        get_db_session,
        create_conversation,
        get_conversation,
        get_all_conversations,
        add_message,
        get_messages,
        save_research_history as db_save_research_history,
        get_all_research_history as db_get_all_research_history
    )
    from src.utils.title_generator import generate_title_with_llm, generate_title_fallback
    DB_AVAILABLE = True
except ImportError as e:
    # è­¦å‘Šã¯å¾Œã§è¡¨ç¤ºï¼ˆstãŒåˆ©ç”¨å¯èƒ½ã«ãªã£ã¦ã‹ã‚‰ï¼‰
    import logging
    logger = logging.getLogger(__name__)
    logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    DB_AVAILABLE = False
except Exception as e:
    # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã‚‚ã‚­ãƒ£ãƒƒãƒ
    import logging
    logger = logging.getLogger(__name__)
    logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    DB_AVAILABLE = False

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€
env_path = project_root / ".env"
if env_path.exists():
    load_dotenv(env_path)
else:
    parent_env = project_root.parent.parent.parent / "API.env"
    if parent_env.exists():
        load_dotenv(parent_env)

# è¨­å®šã‚’èª­ã¿è¾¼ã‚€
try:
    from src.config.settings import Settings
    settings = Settings()
    ENABLE_DB_PERSISTENCE = settings.ENABLE_DB_PERSISTENCE
except ImportError:
    ENABLE_DB_PERSISTENCE = False

# APIã‚µãƒ¼ãƒãƒ¼ã®ãƒ™ãƒ¼ã‚¹URLï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ­ãƒ¼ã‚«ãƒ«ï¼‰
API_BASE_URL = os.getenv("API_BASE_URL", "http://localhost:8000")

# ãƒ­ã‚¬ãƒ¼è¨­å®š
try:
    from src.utils.logger import setup_logger
    logger = setup_logger()
except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ãƒãƒ£ãƒƒãƒˆ",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSSã‚¹ã‚¿ã‚¤ãƒ«
st.markdown("""
<style>
    .stChatMessage {
        padding: 1rem;
    }
    .main .block-container {
        max-width: 1350px;
        padding: 2rem 1rem;
    }
    /* çµæœè¡¨ç¤ºéƒ¨åˆ†ã‚’ä¸­å¤®æƒãˆã§é©åˆ‡ãªå¹…ã«åˆ¶é™ï¼ˆ1.5å€ã«æ‹¡å¤§ï¼‰ */
    .stMarkdown {
        max-width: 1200px;
        margin: 0 auto;
    }
    /* ãƒ¬ãƒãƒ¼ãƒˆè¡¨ç¤ºéƒ¨åˆ†ã®å¹…ã‚’åˆ¶é™ï¼ˆ1.5å€ã«æ‹¡å¤§ï¼‰ */
    div[data-testid="stVerticalBlock"] {
        max-width: 1200px;
        margin: 0 auto;
    }
    /* ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤ºã®å¹…ã‚’åˆ¶é™ï¼ˆ1.5å€ã«æ‹¡å¤§ï¼‰ */
    div[data-testid="stMetricContainer"] {
        max-width: 1200px;
        margin: 0 auto;
    }
    .sidebar .sidebar-content {
        background-color: #f0f2f6;
    }
    .research-status {
        padding: 0.5rem;
        border-radius: 0.5rem;
        margin: 0.5rem 0;
    }
    .status-processing {
        background-color: #e3f2fd;
        color: #1976d2;
    }
    .status-completed {
        background-color: #e8f5e9;
        color: #388e3c;
    }
    .status-failed {
        background-color: #ffebee;
        color: #d32f2f;
    }
    /* ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚¹ã‚¿ã‚¤ãƒ«æ”¹å–„ */
    .stMarkdown code {
        background-color: #f4f4f4;
        padding: 0.2em 0.4em;
        border-radius: 3px;
        font-size: 0.9em;
    }
    .stMarkdown pre {
        background-color: #f8f8f8;
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 1em;
        overflow-x: auto;
    }
    /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ«æ”¹å–„ */
    .stButton > button {
        border-radius: 5px;
        transition: all 0.3s ease;
    }
    .stButton > button:hover {
        transform: translateY(-1px);
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
    }
    /* ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ */
    @media (max-width: 768px) {
        .main .block-container {
            max-width: 100%;
            padding: 1rem;
        }
    }
</style>
""", unsafe_allow_html=True)


# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
def init_session_state():
    """ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã‚’åˆæœŸåŒ–"""
    if "messages" not in st.session_state:
        st.session_state.messages = []
    
    if "research_history" not in st.session_state:
        st.session_state.research_history = []
    
    if "current_research_id" not in st.session_state:
        st.session_state.current_research_id = None
    
    if "research_status" not in st.session_state:
        st.session_state.research_status = None
    
    if "streaming_enabled" not in st.session_state:
        st.session_state.streaming_enabled = True
    
    if "regenerate_prompt" not in st.session_state:
        st.session_state.regenerate_prompt = None
    
    if "regenerate_theme" not in st.session_state:
        st.session_state.regenerate_theme = None
    
    if "regenerate_research_id" not in st.session_state:
        st.session_state.regenerate_research_id = None
    
    if "stop_requested" not in st.session_state:
        st.session_state.stop_requested = False
    
    if "conversation_id" not in st.session_state:
        st.session_state.conversation_id = str(uuid.uuid4())
    
    if "messages_loaded_from_db" not in st.session_state:
        st.session_state.messages_loaded_from_db = False
    
    if "db_warning_shown" not in st.session_state:
        st.session_state.db_warning_shown = False
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
    if DB_AVAILABLE and ENABLE_DB_PERSISTENCE:
        try:
            init_db()
        except Exception as e:
            logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")


# APIé–¢æ•°
def create_research(theme: str, max_iterations: int = 5, enable_human_intervention: bool = False) -> Optional[str]:
    """ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹"""
    url = f"{API_BASE_URL}/research"
    payload = {
        "theme": theme,
        "max_iterations": max_iterations,
        "enable_human_intervention": enable_human_intervention,
        "checkpointer_type": "memory"
    }
    
    try:
        # ãƒªã‚µãƒ¼ãƒä½œæˆã¯æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·ï¼ˆ300ç§’ï¼‰
        # LLMè¦ç´„å‡¦ç†ã‚’å«ã‚€ãŸã‚ã€ååˆ†ãªæ™‚é–“ã‚’ç¢ºä¿
        response = requests.post(url, json=payload, timeout=300)
        response.raise_for_status()
        data = response.json()
        return data["research_id"]
    except requests.exceptions.ConnectionError as e:
        # æ¥ç¶šã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ã‚ˆã‚Šåˆ†ã‹ã‚Šã‚„ã™ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¡¨ç¤º
        error_msg = f"""
**âŒ APIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“**

APIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

**è§£æ±ºæ–¹æ³•:**
1. åˆ¥ã®ã‚¿ãƒ¼ãƒŸãƒŠãƒ«ã§APIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„:
   ```bash
   uvicorn src.api.main:app --reload
   ```
2. APIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ãŸã‚‰ã€ä»¥ä¸‹ã®URLã«ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„:
   - {API_BASE_URL}/health
   - {API_BASE_URL}/docs
3. ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒğŸ¥ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã€ãƒœã‚¿ãƒ³ã§æ¥ç¶šã‚’ç¢ºèªã§ãã¾ã™

**ç¾åœ¨ã®API URL**: `{API_BASE_URL}`
"""
        st.error(error_msg)
        logger.error(f"APIã‚µãƒ¼ãƒãƒ¼æ¥ç¶šã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except requests.exceptions.Timeout as e:
        error_msg = f"""
**â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼**: APIã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆ300ç§’ä»¥å†…ï¼‰

APIã‚µãƒ¼ãƒãƒ¼ãŒãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’å‡¦ç†ä¸­ã§ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚

**è§£æ±ºæ–¹æ³•:**
1. APIã‚µãƒ¼ãƒãƒ¼ã®ãƒ­ã‚°ã‚’ç¢ºèªã—ã¦ãã ã•ã„
2. ãƒªã‚µãƒ¼ãƒãŒé•·æ™‚é–“å®Ÿè¡Œã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„
3. APIã‚µãƒ¼ãƒãƒ¼ãŒæ­£å¸¸ã«å‹•ä½œã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„: `{API_BASE_URL}/health`

**ç¾åœ¨ã®API URL**: `{API_BASE_URL}`
"""
        st.error(error_msg)
        logger.error(f"APIã‚µãƒ¼ãƒãƒ¼ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {e}")
        return None
    except requests.exceptions.HTTPError as e:
        st.error(f"**HTTPã‚¨ãƒ©ãƒ¼**: APIã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒè¿”ã•ã‚Œã¾ã—ãŸã€‚\n\nã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚³ãƒ¼ãƒ‰: {response.status_code}\nè©³ç´°: {e}")
        logger.error(f"APIã‚µãƒ¼ãƒãƒ¼HTTPã‚¨ãƒ©ãƒ¼: {e}")
        return None
    except Exception as e:
        st.error(f"**ãƒªã‚µãƒ¼ãƒä½œæˆã‚¨ãƒ©ãƒ¼**: {e}\n\nAPIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„: `{API_BASE_URL}`")
        logger.error(f"ãƒªã‚µãƒ¼ãƒä½œæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
        return None


def get_research_status(research_id: str) -> Optional[dict]:
    """ãƒªã‚µãƒ¼ãƒã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚’å–å¾—"""
    url = f"{API_BASE_URL}/research/{research_id}/status"
    
    try:
        response = requests.get(url, timeout=5)
        response.raise_for_status()
        return response.json()
    except Exception:
        return None


def get_research_result(research_id: str) -> Optional[dict]:
    """ãƒªã‚µãƒ¼ãƒçµæœã‚’å–å¾—"""
    url = f"{API_BASE_URL}/research/{research_id}"
    
    try:
        response = requests.get(url, timeout=5)
        if response.status_code == 422:
            return None
        response.raise_for_status()
        return response.json()
    except Exception:
        return None


def resume_research(research_id: str, human_input: str) -> bool:
    """ä¸­æ–­ã•ã‚ŒãŸãƒªã‚µãƒ¼ãƒã‚’å†é–‹"""
    url = f"{API_BASE_URL}/research/{research_id}/resume"
    payload = {"human_input": human_input}
    
    try:
        # ãƒªã‚µãƒ¼ãƒå†é–‹ã‚‚æ™‚é–“ãŒã‹ã‹ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ãŸã‚ã€ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚’å»¶é•·ï¼ˆ300ç§’ï¼‰
        # LLMè¦ç´„å‡¦ç†ã‚’å«ã‚€ãŸã‚ã€ååˆ†ãªæ™‚é–“ã‚’ç¢ºä¿
        response = requests.post(url, json=payload, timeout=300)
        response.raise_for_status()
        return True
    except Exception:
        return False


def delete_research(research_id: str) -> bool:
    """ãƒªã‚µãƒ¼ãƒã‚’å‰Šé™¤"""
    url = f"{API_BASE_URL}/research/{research_id}"
    
    try:
        response = requests.delete(url, timeout=5)
        response.raise_for_status()
        return True
    except Exception:
        return False


def check_health() -> tuple[bool, str]:
    """
    ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
    
    Returns:
        (is_healthy, message): ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯çµæœã¨ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    """
    url = f"{API_BASE_URL}/health"
    
    try:
        response = requests.get(url, timeout=5)
        response.raise_for_status()
        data = response.json()
        if data.get("status") == "healthy":
            return True, "âœ… APIã‚µãƒ¼ãƒãƒ¼ã¯æ­£å¸¸ã§ã™"
        else:
            return False, f"âš ï¸ APIã‚µãƒ¼ãƒãƒ¼ã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {data.get('status', 'unknown')}"
    except requests.exceptions.ConnectionError:
        return False, f"âŒ APIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“\n\nAPIã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ã—ã¦ãã ã•ã„:\n```bash\nuvicorn src.api.main:app --reload\n```\n\nç¾åœ¨ã®API URL: `{API_BASE_URL}`"
    except requests.exceptions.Timeout:
        return False, f"â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: APIã‚µãƒ¼ãƒãƒ¼ã‹ã‚‰ã®å¿œç­”ãŒã‚ã‚Šã¾ã›ã‚“\n\nAPI URL: `{API_BASE_URL}`"
    except Exception as e:
        return False, f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}\n\nAPI URL: `{API_BASE_URL}`"


def generate_title_from_theme(theme: str, max_length: int = 50, use_llm: bool = False, draft_content: Optional[str] = None) -> str:
    """
    ãƒ†ãƒ¼ãƒã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
    
    Args:
        theme: èª¿æŸ»ãƒ†ãƒ¼ãƒ
        max_length: æœ€å¤§æ–‡å­—æ•°
        use_llm: LLMã‚’ä½¿ç”¨ã™ã‚‹ã‹
        draft_content: ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ‰ãƒ©ãƒ•ãƒˆå†…å®¹ï¼ˆLLMä½¿ç”¨æ™‚ï¼‰
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸã‚¿ã‚¤ãƒˆãƒ«
    """
    if use_llm and DB_AVAILABLE:
        try:
            return generate_title_with_llm(theme, draft_content, max_length)
        except Exception as e:
            st.warning(f"LLMã‚¿ã‚¤ãƒˆãƒ«ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
            return generate_title_fallback(theme, max_length)
    else:
        return generate_title_fallback(theme, max_length)


def format_research_for_history(research_id: str, theme: str, status: str, title: Optional[str] = None) -> Dict:
    """å±¥æ­´ç”¨ã«ãƒªã‚µãƒ¼ãƒæƒ…å ±ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
    if title is None:
        title = generate_title_from_theme(theme)
    
    return {
        "research_id": research_id,
        "theme": theme,
        "status": status,
        "created_at": datetime.now().isoformat(),
        "title": title
    }


def save_research_to_history(research_info: Dict):
    """ãƒªã‚µãƒ¼ãƒå±¥æ­´ã«ä¿å­˜ï¼ˆã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã¨DBï¼‰"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
    if research_info not in st.session_state.research_history:
        st.session_state.research_history.insert(0, research_info)
        # å±¥æ­´ã¯æœ€å¤§50ä»¶ã¾ã§ä¿æŒ
        if len(st.session_state.research_history) > 50:
            st.session_state.research_history = st.session_state.research_history[:50]
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    if DB_AVAILABLE and ENABLE_DB_PERSISTENCE:
        try:
            db_gen = get_db_session()
            db = next(db_gen, None)
            if db is not None:
                try:
                    db_save_research_history(
                        db=db,
                        research_id=research_info["research_id"],
                        theme=research_info["theme"],
                        status=research_info["status"],
                        title=research_info.get("title"),
                        metadata_json={
                            "created_at": research_info.get("created_at")
                        }
                    )
                finally:
                    db.close()
        except Exception as e:
            logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")


def load_research_history_from_db():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰ãƒªã‚µãƒ¼ãƒå±¥æ­´ã‚’èª­ã¿è¾¼ã‚€"""
    if not DB_AVAILABLE or not ENABLE_DB_PERSISTENCE:
        return
    
    try:
        db_gen = get_db_session()
        db = next(db_gen, None)
        if db is not None:
            try:
                db_history = db_get_all_research_history(db, limit=50)
                # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«åæ˜ 
                for research in db_history:
                    research_info = {
                        "research_id": research.research_id,
                        "theme": research.theme,
                        "status": research.status,
                        "created_at": research.created_at.isoformat() if research.created_at else datetime.now().isoformat(),
                        "title": research.title or research.theme[:50] + "..." if len(research.theme) > 50 else research.theme
                    }
                    # é‡è¤‡ãƒã‚§ãƒƒã‚¯
                    if not any(h["research_id"] == research_info["research_id"] for h in st.session_state.research_history):
                        st.session_state.research_history.append(research_info)
            finally:
                db.close()
    except Exception as e:
        logger.warning(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")


def display_research_result(result: dict, research_id: str = None):
    """ãƒªã‚µãƒ¼ãƒçµæœã‚’è¡¨ç¤º"""
    if not result:
        return
    
    # çµæœè¡¨ç¤ºã‚’ä¸­å¤®æƒãˆã§é©åˆ‡ãªå¹…ã«åˆ¶é™ã™ã‚‹ãŸã‚ã®ã‚³ãƒ³ãƒ†ãƒŠ
    # ã‚³ãƒ³ãƒ†ãƒŠã‚’ä½¿ç”¨ã›ãšã€ç›´æ¥è¡¨ç¤ºï¼ˆãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹å¤‰æ›´æ™‚ã®è¡¨ç¤ºå•é¡Œã‚’å›é¿ï¼‰
    st.markdown("### ğŸ“Š ãƒªã‚µãƒ¼ãƒçµæœ")
    
    # çµ±è¨ˆæƒ…å ±
    if result.get("statistics"):
        stats = result["statistics"]
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›æ•°", stats.get("iterations", 0))
        with col2:
            st.metric("åé›†ã‚½ãƒ¼ã‚¹æ•°", stats.get("sources_collected", 0))
        with col3:
            st.metric("å‡¦ç†æ™‚é–“", f"{stats.get('processing_time_seconds', 0)}ç§’")
    
    # ãƒ¬ãƒãƒ¼ãƒˆ
    if result.get("report") and result["report"].get("draft"):
        st.markdown("### ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆ")
        
        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ãƒœã‚¿ãƒ³ï¼ˆå†ç”Ÿæˆã€åœæ­¢ï¼‰
        col1, col2 = st.columns([1, 4])
        with col1:
            if research_id and st.button("ğŸ”„ å†ç”Ÿæˆ", key=f"regenerate_{research_id}", use_container_width=True):
                # å†ç”Ÿæˆæ©Ÿèƒ½
                theme = result.get("theme", "")
                if theme:
                    st.session_state.regenerate_theme = theme
                    st.session_state.regenerate_research_id = research_id
                    st.rerun()
        
        # ãƒ¬ãƒãƒ¼ãƒˆæœ¬æ–‡ã‚’å‡¦ç†ï¼ˆFootnotesã‚’å‚ç…§ã‚½ãƒ¼ã‚¹ã¸ã®ãƒªãƒ³ã‚¯ã«å¤‰æ›ï¼‰
        report_draft = result["report"]["draft"]
        
        # Footnotesã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ## å‚è€ƒæ–‡çŒ®ï¼‰ã‚’å‰Šé™¤
        # Footnotesã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯ã€Œ## å‚è€ƒæ–‡çŒ®ã€ã‹ã‚‰å§‹ã¾ã‚Šã€æ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆ---ï¼‰ã¾ã§
        import re
        # Footnotesã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‰Šé™¤
        report_draft = re.sub(r'## å‚è€ƒæ–‡çŒ®.*?(?=\n---|\n## |\Z)', '', report_draft, flags=re.DOTALL)
        
        # Footnoteså½¢å¼ï¼ˆ[^1], [^2]ãªã©ï¼‰ã‚’å‚ç…§ã‚½ãƒ¼ã‚¹ã¸ã®ãƒªãƒ³ã‚¯ã«å¤‰æ›
        if result["report"].get("sources"):
            sources = result["report"]["sources"]
            # å„Footnotesã‚’å‚ç…§ã‚½ãƒ¼ã‚¹ã¸ã®ãƒªãƒ³ã‚¯ã«å¤‰æ›
            for i, source in enumerate(sources, 1):
                url = source.get('url', 'N/A')
                # [^æ•°å­—]å½¢å¼ã‚’[æ•°å­—](URL)å½¢å¼ã«å¤‰æ›
                footnote_pattern = rf'\[\^{i}\]'
                link_replacement = f'[{i}]({url})'
                report_draft = re.sub(footnote_pattern, link_replacement, report_draft)
        
        # Markdownãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’å«ã‚€ï¼‰
        # Streamlitã¯è‡ªå‹•çš„ã«ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¾ã™
        st.markdown(report_draft, unsafe_allow_html=False)
        
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
        draft_content = report_draft
        
        # å‚ç…§ã‚½ãƒ¼ã‚¹æƒ…å ±ã‚’è¿½åŠ ï¼ˆFootnotesã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¯è¡¨ç¤ºã—ãªã„ï¼‰
        if result["report"].get("sources"):
            draft_content += "\n\n---\n\n## ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹\n\n"
            draft_content += f"æœ¬ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã® {len(result['report']['sources'])} ä»¶ã®ã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚\n\n"
            
            for i, source in enumerate(result["report"]["sources"], 1):
                draft_content += f"### {i}. {source.get('title', 'N/A')}\n\n"
                draft_content += f"- **URL**: [{source.get('url', 'N/A')}]({source.get('url', 'N/A')})\n"
                if source.get("summary"):
                    # è¦ç´„ã¯å…¨æ–‡ã‚’è¡¨ç¤º
                    draft_content += f"- **è¦ç´„**: {source['summary']}\n"
                if source.get("relevance_score") is not None:
                    draft_content += f"- **é–¢é€£æ€§ã‚¹ã‚³ã‚¢**: {source['relevance_score']:.2f}\n"
                if source.get("source"):
                    draft_content += f"- **ã‚½ãƒ¼ã‚¹**: {source['source']}\n"
                draft_content += "\n"
        
        st.download_button(
            label="ğŸ“¥ ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=draft_content,
            file_name=f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.md",
            mime="text/markdown"
        )
        
        # å‚ç…§ã‚½ãƒ¼ã‚¹
        if result["report"].get("sources"):
            sources = result["report"]["sources"]
            sources_key = f"sources_selection_{research_id if research_id else 'default'}"
            expander_state_key = f"expander_open_{sources_key}"
            
            # expanderã®é–‹é–‰çŠ¶æ…‹ã‚’æ˜ç¤ºçš„ã«ç®¡ç†ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§é–‹ãï¼‰
            if expander_state_key not in st.session_state:
                st.session_state[expander_state_key] = True
            
            with st.expander(f"ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹ ({len(sources)}ä»¶)", expanded=st.session_state[expander_state_key]):
                    # é¸æŠçŠ¶æ…‹ã®åˆæœŸåŒ–
                    if sources_key not in st.session_state:
                        st.session_state[sources_key] = []
                    
                    # å…¨é¸æŠ/å…¨è§£é™¤ãƒœã‚¿ãƒ³
                    col1, col2 = st.columns(2)
                    with col1:
                        if st.button("âœ… ã™ã¹ã¦é¸æŠ", key=f"select_all_{sources_key}"):
                            st.session_state[sources_key] = list(range(len(sources)))
                            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®keyã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹çŠ¶æ…‹ã‚‚åŒæœŸï¼ˆã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆå‰ã«è¨­å®šï¼‰
                            for i in range(len(sources)):
                                checkbox_key = f"source_check_{sources_key}_{i}"
                                st.session_state[checkbox_key] = True
                            st.rerun()
                    with col2:
                        if st.button("âŒ ã™ã¹ã¦è§£é™¤", key=f"deselect_all_{sources_key}"):
                            st.session_state[sources_key] = []
                            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®keyã§ç®¡ç†ã•ã‚Œã¦ã„ã‚‹çŠ¶æ…‹ã‚‚åŒæœŸï¼ˆã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆå‰ã«è¨­å®šï¼‰
                            for i in range(len(sources)):
                                checkbox_key = f"source_check_{sources_key}_{i}"
                                st.session_state[checkbox_key] = False
                            st.rerun()
                    
                    # é¸æŠã•ã‚ŒãŸã‚½ãƒ¼ã‚¹æ•°ã‚’è¡¨ç¤º
                    selected_count = len(st.session_state[sources_key])
                    if selected_count > 0:
                        st.info(f"ğŸ“Œ {selected_count}ä»¶ã®ã‚½ãƒ¼ã‚¹ãŒé¸æŠã•ã‚Œã¦ã„ã¾ã™")
                    
                    # å„ã‚½ãƒ¼ã‚¹ã«ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’è¿½åŠ 
                    # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®çŠ¶æ…‹å¤‰æ›´ã‚’åŠ¹ç‡çš„ã«å‡¦ç†ï¼ˆé«˜é€ŸåŒ–ï¼‰
                    for i, source in enumerate(sources):
                        col_check, col_content = st.columns([1, 20])
                        with col_check:
                            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ã‚­ãƒ¼ï¼ˆStreamlitã®çŠ¶æ…‹ç®¡ç†ã«ä½¿ç”¨ï¼‰
                            checkbox_key = f"source_check_{sources_key}_{i}"
                            
                            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®ç¾åœ¨ã®çŠ¶æ…‹ã‚’å–å¾—ï¼ˆsources_keyãƒªã‚¹ãƒˆã‹ã‚‰åˆ¤æ–­ï¼‰
                            is_selected = i in st.session_state[sources_key]
                            
                            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã®åˆæœŸçŠ¶æ…‹ã‚’è¨­å®šï¼ˆåˆå›ã®ã¿ã€ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆå‰ã«è¨­å®šï¼‰
                            # æ³¨æ„: ã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆä½œæˆå¾Œã«st.session_stateã§å€¤ã‚’è¨­å®šã™ã‚‹ã¨è­¦å‘ŠãŒè¡¨ç¤ºã•ã‚Œã‚‹
                            if checkbox_key not in st.session_state:
                                st.session_state[checkbox_key] = is_selected
                            
                            # ãƒã‚§ãƒƒã‚¯ãƒœãƒƒã‚¯ã‚¹ã‚’è¡¨ç¤º
                            # valueãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€st.session_stateã§å€¤ã‚’å¤‰æ›´ã—ãªã„
                            new_selected = st.checkbox(
                                "",
                                value=is_selected,  # sources_keyãƒªã‚¹ãƒˆã‹ã‚‰ç›´æ¥åˆ¤æ–­ã—ãŸå€¤ã‚’ä½¿ç”¨
                                key=checkbox_key,
                                label_visibility="collapsed"
                            )
                            
                            # çŠ¶æ…‹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®ã¿session_stateã‚’æ›´æ–°
                            if new_selected != is_selected:
                                # sources_keyãƒªã‚¹ãƒˆã‚’æ›´æ–°
                                if new_selected:
                                    # è¿½åŠ ï¼ˆé‡è¤‡ãƒã‚§ãƒƒã‚¯ã‚’é¿ã‘ã‚‹ï¼‰
                                    if i not in st.session_state[sources_key]:
                                        st.session_state[sources_key].append(i)
                                else:
                                    # å‰Šé™¤ï¼ˆåŠ¹ç‡çš„ã«ï¼‰
                                    try:
                                        st.session_state[sources_key].remove(i)
                                    except ValueError:
                                        pass  # æ—¢ã«å‰Šé™¤ã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ä½•ã‚‚ã—ãªã„
                                # expanderã®é–‹é–‰çŠ¶æ…‹ã‚’ä¿æŒï¼ˆé–‹ã„ãŸã¾ã¾ã«ã™ã‚‹ï¼‰
                                st.session_state[expander_state_key] = True
                                st.rerun()
                        
                        with col_content:
                            st.markdown(f"**{i+1}. {source.get('title', 'N/A')}**")
                            url = source.get('url', 'N/A')
                            st.markdown(f"- URL: {url}")
                            
                            if source.get("summary"):
                                st.caption(source["summary"][:200] + "..." if len(source["summary"]) > 200 else source["summary"])
                            if source.get("relevance_score"):
                                st.caption(f"é–¢é€£æ€§ã‚¹ã‚³ã‚¢: {source['relevance_score']:.2f}")
                            
                            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯é–¢é€£æ€§ã‚¹ã‚³ã‚¢ã®å¾Œã«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                            is_pdf_url = url.lower().endswith('.pdf') or '.pdf' in url.lower() if url != 'N/A' else False
                            if is_pdf_url and url != 'N/A':
                                pdf_download_key = f"pdf_download_{sources_key}_{i}"
                                if pdf_download_key not in st.session_state:
                                    st.session_state[pdf_download_key] = None
                                
                                if st.button(f"ğŸ“¥ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", key=f"fetch_pdf_{sources_key}_{i}", use_container_width=False):
                                    try:
                                        with st.spinner("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ä¸­..."):
                                            headers = {
                                                "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                                                "Accept": "application/pdf,application/octet-stream,*/*",
                                            }
                                            response = requests.get(url, timeout=30, headers=headers, allow_redirects=True)
                                            response.raise_for_status()
                                            st.session_state[pdf_download_key] = response.content
                                            st.success("PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
                                            st.rerun()
                                    except Exception as e:
                                        st.error(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                                
                                # PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒå–å¾—æ¸ˆã¿ã®å ´åˆã¯ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                                if st.session_state[pdf_download_key] is not None:
                                    pdf_filename = url.split('/')[-1].split('?')[0] or f"source_{i+1}.pdf"
                                    st.download_button(
                                        label=f"ğŸ“¥ {pdf_filename}ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                        data=st.session_state[pdf_download_key],
                                        file_name=pdf_filename,
                                        mime="application/pdf",
                                        key=f"download_pdf_file_{sources_key}_{i}",
                                        use_container_width=False
                                    )
                    
                    # PDFãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                    st.divider()
                    selected_count = len(st.session_state[sources_key])
                    if selected_count > 0:
                        if PDF_AVAILABLE:
                            # PDFç”Ÿæˆã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                            pdf_key = f"pdf_buffer_{sources_key}"
                            pdf_filename_key = f"pdf_filename_{sources_key}"
                            
                            # PDFç”Ÿæˆãƒœã‚¿ãƒ³ï¼ˆå„ã‚½ãƒ¼ã‚¹ã”ã¨ã«å€‹åˆ¥ã®PDFã‚’ç”Ÿæˆï¼‰
                            if st.button(
                                f"ğŸ“¥ é¸æŠã—ãŸ{selected_count}ä»¶ã®ã‚½ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸ã‚’PDFã§ç”Ÿæˆ",
                                key=f"generate_pdf_{sources_key}",
                                use_container_width=True
                            ):
                                try:
                                    with st.spinner(f"ğŸ“„ PDFã‚’ç”Ÿæˆä¸­... å„URLå…ˆã®ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦ã„ã¾ã™ (0/{selected_count})"):
                                        # å„ã‚½ãƒ¼ã‚¹ã”ã¨ã«å€‹åˆ¥ã®PDFã‚’ç”Ÿæˆ
                                        pdf_buffers_key = f"pdf_buffers_{sources_key}"
                                        pdf_filenames_key = f"pdf_filenames_{sources_key}"
                                        
                                        pdf_buffers = {}
                                        pdf_filenames = {}
                                        
                                        selected_indices = st.session_state[sources_key]
                                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                                        
                                        for idx, source_idx in enumerate(selected_indices, 1):
                                            if source_idx < 0 or source_idx >= len(sources):
                                                continue
                                            
                                            source = sources[source_idx]
                                            source_title = source.get('title', 'source')
                                            source_safe = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in source_title[:50])
                                            
                                            # å˜ä¸€ã‚½ãƒ¼ã‚¹ç”¨ã®PDFã‚’ç”Ÿæˆ
                                            pdf_buffer = generate_single_source_pdf(
                                                source,
                                                source_idx,
                                                result.get("theme", "ãƒªã‚µãƒ¼ãƒ")
                                            )
                                            
                                            filename = f"{source_safe}_{timestamp}.pdf"
                                            pdf_buffers[source_idx] = pdf_buffer.getvalue()
                                            pdf_filenames[source_idx] = filename
                                        
                                        # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
                                        st.session_state[pdf_buffers_key] = pdf_buffers
                                        st.session_state[pdf_filenames_key] = pdf_filenames
                                        
                                        st.success(f"âœ… {len(pdf_buffers)}ä»¶ã®PDFã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
                                except Exception as e:
                                    st.error(f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
                                    logger.error(f"PDFç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}", exc_info=True)
                            
                            # ç”Ÿæˆã•ã‚ŒãŸPDFã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã‚’è¡¨ç¤º
                            pdf_buffers_key = f"pdf_buffers_{sources_key}"
                            pdf_filenames_key = f"pdf_filenames_{sources_key}"
                            
                            if pdf_buffers_key in st.session_state and pdf_filenames_key in st.session_state:
                                pdf_buffers = st.session_state[pdf_buffers_key]
                                pdf_filenames = st.session_state[pdf_filenames_key]
                                
                                if pdf_buffers and pdf_filenames:
                                    st.markdown("### ğŸ“¥ ç”Ÿæˆã•ã‚ŒãŸPDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
                                    for source_idx in st.session_state[sources_key]:
                                        if source_idx in pdf_buffers and source_idx in pdf_filenames:
                                            source = sources[source_idx]
                                            source_title = source.get('title', 'N/A')
                                            filename = pdf_filenames[source_idx]
                                            
                                            st.download_button(
                                                label=f"ğŸ“¥ {source_title} ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                                                data=pdf_buffers[source_idx],
                                                file_name=filename,
                                                mime="application/pdf",
                                                key=f"download_pdf_{sources_key}_{source_idx}",
                                                use_container_width=False
                                            )
                        else:
                            st.warning("PDFç”Ÿæˆæ©Ÿèƒ½ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯reportlabã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„: pip install reportlab")
                    else:
                        st.info("ğŸ“Œ PDFã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã«ã¯ã€ä¸Šè¨˜ã®ã‚½ãƒ¼ã‚¹ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚")


def display_progress(status_data: dict):
    """é€²æ—æƒ…å ±ã‚’è¡¨ç¤º"""
    if not status_data:
        return
    
    status = status_data.get("status", "unknown")
    
    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã«å¿œã˜ãŸã‚¹ã‚¿ã‚¤ãƒ«
    status_colors = {
        "processing": ("å‡¦ç†ä¸­", "status-processing"),
        "completed": ("å®Œäº†", "status-completed"),
        "failed": ("å¤±æ•—", "status-failed"),
        "started": ("é–‹å§‹", "status-processing"),
        "interrupted": ("ä¸­æ–­", "status-processing")
    }
    
    status_text, status_class = status_colors.get(status, ("ä¸æ˜", ""))
    
    if status_data.get("progress"):
        progress = status_data["progress"]
        st.markdown(f'<div class="research-status {status_class}">', unsafe_allow_html=True)
        st.write(f"**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: {status_text}")
        st.write(f"**é€²æ—**: {progress.get('current_iteration', 0)}/{progress.get('max_iterations', 0)} ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
        st.write(f"**ç¾åœ¨ã®ãƒãƒ¼ãƒ‰**: {progress.get('current_node', 'unknown')}")
        
        if status_data.get("statistics"):
            stats = status_data["statistics"]
            st.write(f"**åé›†ã‚½ãƒ¼ã‚¹æ•°**: {stats.get('sources_collected', 0)}")
        st.markdown('</div>', unsafe_allow_html=True)


# ã‚µã‚¤ãƒ‰ãƒãƒ¼
def render_sidebar():
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    with st.sidebar:
        st.title("ğŸ” ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ")
        
        # æ–°è¦ãƒãƒ£ãƒƒãƒˆãƒœã‚¿ãƒ³
        if st.button("â• æ–°è¦ãƒãƒ£ãƒƒãƒˆ", use_container_width=True):
            st.session_state.messages = []
            st.session_state.current_research_id = None
            st.session_state.research_status = None
            st.session_state.conversation_id = str(uuid.uuid4())
            st.rerun()
        
        # DBã‹ã‚‰å±¥æ­´ã‚’èª­ã¿è¾¼ã‚€ãƒœã‚¿ãƒ³
        if DB_AVAILABLE and ENABLE_DB_PERSISTENCE:
            if st.button("ğŸ”„ DBã‹ã‚‰å±¥æ­´ã‚’èª­ã¿è¾¼ã¿", use_container_width=True):
                load_research_history_from_db()
                st.success("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å±¥æ­´ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
                st.rerun()
        elif not ENABLE_DB_PERSISTENCE:
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãŒåˆ©ç”¨ã§ããªã„å ´åˆã®æƒ…å ±è¡¨ç¤º
            st.info("â„¹ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ°¸ç¶šåŒ–ã¯ç„¡åŠ¹ã§ã™ã€‚è¨­å®šæ–¹æ³•ã¯README_DB.mdã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚")
        
        st.divider()
        
        # å±¥æ­´ã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("ğŸ“œ å±¥æ­´")
        
        if st.session_state.research_history:
            for idx, research in enumerate(st.session_state.research_history):
                col1, col2 = st.columns([4, 1])
                with col1:
                    if st.button(
                        research["title"],
                        key=f"history_{research['research_id']}",
                        use_container_width=True
                    ):
                        st.session_state.current_research_id = research["research_id"]
                        st.rerun()
                
                with col2:
                    if st.button("ğŸ—‘ï¸", key=f"delete_{research['research_id']}"):
                        delete_research(research["research_id"])
                        st.session_state.research_history = [
                            h for h in st.session_state.research_history
                            if h["research_id"] != research["research_id"]
                        ]
                        if st.session_state.current_research_id == research["research_id"]:
                            st.session_state.current_research_id = None
                        st.rerun()
        else:
            st.caption("å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")
        
        st.divider()
        
        # è¨­å®šã‚»ã‚¯ã‚·ãƒ§ãƒ³
        st.subheader("âš™ï¸ è¨­å®š")
        
        max_iterations = st.slider(
            "æœ€å¤§ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æ•°",
            min_value=1,
            max_value=10,
            value=5,
            key="max_iterations"
        )
        
        enable_human_intervention = st.checkbox(
            "äººé–“ä»‹å…¥ã‚’æœ‰åŠ¹åŒ–",
            value=False,
            key="enable_human_intervention"
        )
        
        # ã‚¿ã‚¤ãƒˆãƒ«è‡ªå‹•ç”Ÿæˆã®è¨­å®š
        auto_generate_title = st.checkbox(
            "ã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªå‹•ç”Ÿæˆ",
            value=True,
            key="auto_generate_title",
            help="ãƒªã‚µãƒ¼ãƒå®Œäº†æ™‚ã«LLMã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’è‡ªå‹•ç”Ÿæˆã—ã¾ã™"
        )
        
        st.divider()
        
        # ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
        if st.button("ğŸ¥ ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯", use_container_width=True):
            is_healthy, message = check_health()
            if is_healthy:
                st.success(message)
            else:
                st.error(message)
                st.markdown("---")
                st.markdown("### ğŸ“ èµ·å‹•æ‰‹é †")
                st.code(f"""
# æ–¹æ³•1: èµ·å‹•ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
python run_api_server.py

# æ–¹æ³•2: uvicornã‚’ç›´æ¥å®Ÿè¡Œ
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„
cd {project_root}
uvicorn src.api.main:app --reload

# æ–¹æ³•3: Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦å®Ÿè¡Œ
python -m uvicorn src.api.main:app --reload
""", language="bash")
                st.info(f"**ç¾åœ¨ã®API URL**: `{API_BASE_URL}`\n\nç’°å¢ƒå¤‰æ•° `API_BASE_URL` ã§å¤‰æ›´ã§ãã¾ã™ã€‚")


# ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„
def render_main_content():
    """ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°"""
    st.title("ğŸ” ãƒªã‚µãƒ¼ãƒã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ - ãƒãƒ£ãƒƒãƒˆ")
    
    # APIã‚µãƒ¼ãƒãƒ¼ã®æ¥ç¶šçŠ¶æ…‹ã‚’è¡¨ç¤º
    is_healthy, health_message = check_health()
    if not is_healthy:
        with st.expander("âš ï¸ APIã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ - èµ·å‹•æ–¹æ³•", expanded=True):
            st.error(health_message)
            st.markdown("### ğŸ“ èµ·å‹•æ‰‹é †")
            st.code(f"""
# Windows: ãƒãƒƒãƒãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ç”¨ï¼ˆæ¨å¥¨ï¼‰
start_api_server.bat

# ã¾ãŸã¯ã€Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’ä½¿ç”¨
python run_api_server.py

# ã¾ãŸã¯ã€uvicornã‚’ç›´æ¥å®Ÿè¡Œ
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‹ã‚‰å®Ÿè¡Œã—ã¦ãã ã•ã„
cd {project_root}
uvicorn src.api.main:app --reload

# ã¾ãŸã¯ã€Pythonãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã¨ã—ã¦å®Ÿè¡Œ
python -m uvicorn src.api.main:app --reload
""", language="bash")
            st.info(f"**ç¾åœ¨ã®API URL**: `{API_BASE_URL}`\n\nç’°å¢ƒå¤‰æ•° `API_BASE_URL` ã§å¤‰æ›´ã§ãã¾ã™ã€‚")
            st.markdown("---")
    
    # DBã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚€ï¼ˆåˆå›ã®ã¿ï¼‰
    if DB_AVAILABLE and ENABLE_DB_PERSISTENCE and not st.session_state.get("messages_loaded_from_db", False):
        try:
            db_gen = get_db_session()
            db = next(db_gen, None)
            if db is not None:
                try:
                    db_messages = get_messages(db, st.session_state.conversation_id)
                    if db_messages and not st.session_state.messages:
                        # DBã‹ã‚‰ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã‚€
                        for db_msg in db_messages:
                            st.session_state.messages.append({
                                "role": db_msg.role,
                                "content": db_msg.content
                            })
                finally:
                    db.close()
            st.session_state.messages_loaded_from_db = True
        except Exception as e:
            logger.warning(f"DBãƒ¡ãƒƒã‚»ãƒ¼ã‚¸èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
    
    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´ã‚’è¡¨ç¤º
    for idx, msg in enumerate(st.session_state.messages):
        with st.chat_message(msg["role"]):
            # Markdownãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°ï¼ˆã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ãƒã‚¤ãƒ©ã‚¤ãƒˆã‚’å«ã‚€ï¼‰
            # Streamlitã¯è‡ªå‹•çš„ã«ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚·ãƒ³ã‚¿ãƒƒã‚¯ã‚¹ãƒã‚¤ãƒ©ã‚¤ãƒˆã—ã¾ã™
            st.markdown(msg["content"], unsafe_allow_html=False)
            
            # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å†ç”Ÿæˆãƒœã‚¿ãƒ³ã‚’è¿½åŠ 
            if msg["role"] == "assistant" and idx > 0:
                # ç›´å‰ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—
                if idx > 0 and st.session_state.messages[idx - 1]["role"] == "user":
                    user_prompt = st.session_state.messages[idx - 1]["content"]
                    if st.button("ğŸ”„ å†ç”Ÿæˆ", key=f"regenerate_msg_{idx}", use_container_width=False):
                        st.session_state.regenerate_prompt = user_prompt
                        st.rerun()
    
    # ç¾åœ¨ã®ãƒªã‚µãƒ¼ãƒã®é€²æ—ã‚’è¡¨ç¤ºï¼ˆé€²æ—è¡¨ç¤ºã¯éè¡¨ç¤ºã€çµæœè¡¨ç¤ºã¯è¡¨ç¤ºï¼‰
    if st.session_state.current_research_id:
        status_data = get_research_status(st.session_state.current_research_id)
        if status_data:
            # display_progress(status_data)  # é€²æ—è¡¨ç¤ºã¯éè¡¨ç¤º
            
            # å®Œäº†ã—ãŸå ´åˆã¯çµæœã‚’è¡¨ç¤º
            if status_data.get("status") == "completed":
                result = get_research_result(st.session_state.current_research_id)
                if result:
                    display_research_result(result, st.session_state.current_research_id)
            
            # ä¸­æ–­ã•ã‚ŒãŸå ´åˆ
            elif status_data.get("status") == "interrupted":
                st.warning("â¸ï¸ ãƒªã‚µãƒ¼ãƒãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸã€‚äººé–“ã®å…¥åŠ›ãŒå¿…è¦ã§ã™ã€‚")
                human_input = st.text_input("å…¥åŠ›ã—ã¦ãã ã•ã„:", key="human_input")
                if st.button("å†é–‹"):
                    if human_input:
                        if resume_research(st.session_state.current_research_id, human_input):
                            st.success("ãƒªã‚µãƒ¼ãƒã‚’å†é–‹ã—ã¾ã—ãŸ")
                            st.rerun()
    
    # å†ç”Ÿæˆå‡¦ç†ï¼ˆå„ªå…ˆåº¦: å†ç”Ÿæˆ > ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ï¼‰
    regenerate_prompt = st.session_state.get("regenerate_prompt")
    regenerate_theme = st.session_state.get("regenerate_theme")
    
    if regenerate_prompt:
        prompt = regenerate_prompt
        st.session_state.regenerate_prompt = None
        # æœ€å¾Œã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
        if st.session_state.messages and st.session_state.messages[-1]["role"] == "assistant":
            st.session_state.messages.pop()
    elif regenerate_theme:
        prompt = regenerate_theme
        st.session_state.regenerate_theme = None
        st.session_state.regenerate_research_id = None
    else:
        prompt = None
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›
    chat_input = st.chat_input("èª¿æŸ»ãƒ†ãƒ¼ãƒã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...")
    if chat_input:
        prompt = chat_input
    
    # ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹ï¼ˆå†ç”Ÿæˆã¾ãŸã¯æ–°è¦å…¥åŠ›ï¼‰
    if prompt:
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ ï¼ˆæ–°è¦ã®å ´åˆã®ã¿ï¼‰
        if not any(msg["content"] == prompt for msg in st.session_state.messages if msg["role"] == "user"):
            st.session_state.messages.append({"role": "user", "content": prompt})
            
            # DBã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
            if DB_AVAILABLE and ENABLE_DB_PERSISTENCE:
                try:
                    db_gen = get_db_session()
                    db = next(db_gen, None)
                    if db is not None:
                        try:
                            add_message(db, st.session_state.conversation_id, "user", prompt)
                        finally:
                            db.close()
                except Exception as e:
                    logger.warning(f"DBãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
        
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹
        with st.chat_message("assistant"):
            with st.spinner("ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹ã—ã¦ã„ã¾ã™..."):
                research_id = create_research(
                    theme=prompt,
                    max_iterations=st.session_state.get("max_iterations", 5),
                    enable_human_intervention=st.session_state.get("enable_human_intervention", False)
                )
                
                if research_id:
                    st.session_state.current_research_id = research_id
                    
                    # å±¥æ­´ã«ä¿å­˜
                    title = None
                    if st.session_state.get("auto_generate_title", True):
                        # ã‚¿ã‚¤ãƒˆãƒ«ã¯å¾Œã§ç”Ÿæˆï¼ˆå®Œäº†æ™‚ã«ï¼‰
                        title = generate_title_from_theme(prompt, use_llm=False)
                    research_info = format_research_for_history(
                        research_id, prompt, "started", title=title
                    )
                    save_research_to_history(research_info)
                    
                    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
                    response = f"ãƒªã‚µãƒ¼ãƒã‚’é–‹å§‹ã—ã¾ã—ãŸã€‚\n\n**ãƒªã‚µãƒ¼ãƒID**: `{research_id}`\n\né€²æ—ã‚’ç›£è¦–ã—ã¦ã„ã¾ã™..."
                    st.markdown(response)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                    
                    # DBã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
                    if DB_AVAILABLE and ENABLE_DB_PERSISTENCE:
                        try:
                            db_gen = get_db_session()
                            db = next(db_gen, None)
                            if db is not None:
                                try:
                                    add_message(db, st.session_state.conversation_id, "assistant", response)
                                finally:
                                    db.close()
                        except Exception as e:
                            logger.warning(f"DBãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                    
                    # é€²æ—ã‚’ç›£è¦–
                    monitor_research_progress(research_id)
                else:
                    # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯æ—¢ã«create_research()ã§è¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹
                    error_msg = f"ãƒªã‚µãƒ¼ãƒã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚\n\n**APIã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚**\n\nèµ·å‹•æ–¹æ³•:\n```bash\nuvicorn src.api.main:app --reload\n```\n\nAPI URL: `{API_BASE_URL}`"
                    st.session_state.messages.append({"role": "assistant", "content": error_msg})


def stop_research(research_id: str) -> bool:
    """ãƒªã‚µãƒ¼ãƒã‚’åœæ­¢ï¼ˆå‰Šé™¤ï¼‰"""
    # ç¾çŠ¶ã¯DELETEã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’ä½¿ç”¨
    # å°†æ¥çš„ã«ã¯å°‚ç”¨ã®åœæ­¢ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®Ÿè£…
    return delete_research(research_id)


def monitor_research_progress(research_id: str):
    """ãƒªã‚µãƒ¼ãƒã®é€²æ—ã‚’ç›£è¦–ï¼ˆã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œï¼‰"""
    progress_placeholder = st.empty()
    status_placeholder = st.empty()
    max_wait_time = 600  # 10åˆ†
    check_interval = 1  # 1ç§’ï¼ˆã‚ˆã‚Šãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã«æ›´æ–°ï¼‰
    elapsed_time = 0
    last_iteration = -1
    last_sources_count = -1
    last_node = None
    
    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼
    progress_bar = st.progress(0)
    
    # åœæ­¢ãƒœã‚¿ãƒ³
    stop_button_placeholder = st.empty()
    
    # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ›´æ–°ç”¨ã®ã‚³ãƒ³ãƒ†ãƒŠ
    realtime_info = st.empty()
    
    while elapsed_time < max_wait_time:
        # åœæ­¢ãƒœã‚¿ãƒ³ã®è¡¨ç¤ºï¼ˆå‡¦ç†ä¸­ã®å ´åˆã®ã¿ï¼‰
        status_data = get_research_status(research_id)
        
        if not status_data:
            break
        
        status = status_data.get("status")
        
        # åœæ­¢ãƒœã‚¿ãƒ³ï¼ˆå‡¦ç†ä¸­ã®å ´åˆã®ã¿è¡¨ç¤ºï¼‰
        if status in ["processing", "started"]:
            with stop_button_placeholder.container():
                if st.button("â¹ï¸ åœæ­¢", key=f"stop_{research_id}", use_container_width=True):
                    if stop_research(research_id):
                        st.warning("ãƒªã‚µãƒ¼ãƒã‚’åœæ­¢ã—ã¾ã—ãŸ")
                        st.session_state.stop_requested = True
                        break
        
        # é€²æ—ã‚’è¡¨ç¤ºï¼ˆéè¡¨ç¤ºï¼‰
        # with progress_placeholder.container():
        #     display_progress(status_data)
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼ã‚’æ›´æ–°
        if status_data.get("progress"):
            progress = status_data["progress"]
            current_iter = progress.get("current_iteration", 0)
            max_iter = progress.get("max_iterations", 1)
            current_node = progress.get("current_node", "unknown")
            progress_value = min(current_iter / max_iter, 1.0) if max_iter > 0 else 0
            progress_bar.progress(progress_value)
            
            # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æƒ…å ±ã‚’æ›´æ–°
            sources_count = 0
            if status_data.get("statistics"):
                sources_count = status_data["statistics"].get("sources_collected", 0)
            
            # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿æ›´æ–°ï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å‘ä¸Šï¼‰
            if (current_iter > last_iteration or 
                sources_count > last_sources_count or 
                current_node != last_node):
                
                with realtime_info.container():
                    col1, col2 = st.columns(2)
                    with col1:
                        st.caption(f"ğŸ“Š ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³: {current_iter}/{max_iter}")
                    with col2:
                        st.caption(f"ğŸ“š ã‚½ãƒ¼ã‚¹æ•°: {sources_count}")
                    if current_node != "unknown":
                        st.caption(f"âš™ï¸ ç¾åœ¨ã®ãƒãƒ¼ãƒ‰: {current_node}")
                
                # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãŒé€²ã‚“ã å ´åˆã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æ›´æ–°
                if current_iter > last_iteration:
                    with status_placeholder.container():
                        st.info(f"ğŸ”„ ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {current_iter}/{max_iter} ã‚’å®Ÿè¡Œä¸­...")
                    last_iteration = current_iter
                
                last_sources_count = sources_count
                last_node = current_node
        
        # å®Œäº†ã¾ãŸã¯å¤±æ•—
        if status in ["completed", "failed"]:
            stop_button_placeholder.empty()
            progress_bar.empty()
            status_placeholder.empty()
            realtime_info.empty()
            
            if status == "completed":
                result = get_research_result(research_id)
                if result:
                    st.success("âœ… ãƒªã‚µãƒ¼ãƒãŒå®Œäº†ã—ã¾ã—ãŸï¼")
                    display_research_result(result)  # èª¿æŸ»çµæœã‚’è¡¨ç¤º
                    
                    # ãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                    save_report_to_file(result, research_id)
                    
                    # å±¥æ­´ã‚’æ›´æ–°ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ã‚‚æ›´æ–°ï¼‰
                    for research in st.session_state.research_history:
                        if research["research_id"] == research_id:
                            research["status"] = "completed"
                            # ã‚¿ã‚¤ãƒˆãƒ«è‡ªå‹•ç”ŸæˆãŒæœ‰åŠ¹ãªå ´åˆã€ã‚ˆã‚Šè‰¯ã„ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
                            if st.session_state.get("auto_generate_title", True):
                                # ãƒ†ãƒ¼ãƒã¨çµæœã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
                                theme = result.get("theme", research.get("theme", ""))
                                draft_content = None
                                if result.get("report") and result["report"].get("draft"):
                                    draft_content = result["report"]["draft"]
                                
                                # LLMã‚’ä½¿ç”¨ã—ã¦ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç”Ÿæˆ
                                title = generate_title_from_theme(
                                    theme,
                                    use_llm=True,
                                    draft_content=draft_content
                                )
                                research["title"] = title
                                
                                # DBã®ã‚¿ã‚¤ãƒˆãƒ«ã‚‚æ›´æ–°
                                if DB_AVAILABLE and ENABLE_DB_PERSISTENCE:
                                    try:
                                        db_gen = get_db_session()
                                        db = next(db_gen, None)
                                        if db is not None:
                                            try:
                                                db_save_research_history(
                                                    db=db,
                                                    research_id=research_id,
                                                    theme=theme,
                                                    status="completed",
                                                    title=title,
                                                    metadata_json=result.get("statistics")
                                                )
                                            finally:
                                                db.close()
                                    except Exception as e:
                                        logger.warning(f"DBã‚¿ã‚¤ãƒˆãƒ«æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
                            break
                    
                    # å®Œäº†ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ 
                    completion_msg = f"âœ… ãƒªã‚µãƒ¼ãƒãŒå®Œäº†ã—ã¾ã—ãŸï¼\n\n"
                    completion_msg += f"- ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›æ•°: {result.get('statistics', {}).get('iterations', 0)}\n"
                    completion_msg += f"- åé›†ã‚½ãƒ¼ã‚¹æ•°: {result.get('statistics', {}).get('sources_collected', 0)}\n"
                    if result.get("report") and result["report"].get("draft"):
                        completion_msg += f"\nãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚ä¸Šè¨˜ã®çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’ã”ç¢ºèªãã ã•ã„ã€‚"
                    
                    st.session_state.messages.append({"role": "assistant", "content": completion_msg})
                    
                    # DBã«ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¿å­˜
                    if DB_AVAILABLE and ENABLE_DB_PERSISTENCE:
                        try:
                            db_gen = get_db_session()
                            db = next(db_gen, None)
                            if db is not None:
                                try:
                                    add_message(db, st.session_state.conversation_id, "assistant", completion_msg)
                                finally:
                                    db.close()
                        except Exception as e:
                            logger.warning(f"DBãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
                else:
                    st.error("çµæœã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ")
            else:
                st.error("âŒ ãƒªã‚µãƒ¼ãƒãŒå¤±æ•—ã—ã¾ã—ãŸ")
                st.session_state.messages.append({"role": "assistant", "content": "âŒ ãƒªã‚µãƒ¼ãƒãŒå¤±æ•—ã—ã¾ã—ãŸ"})
            
            break
        
        # ä¸­æ–­
        elif status == "interrupted":
            progress_bar.empty()
            stop_button_placeholder.empty()
            realtime_info.empty()
            st.warning("â¸ï¸ ãƒªã‚µãƒ¼ãƒãŒä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
            break
        
        # åœæ­¢ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒæ¥ãŸå ´åˆ
        if st.session_state.get("stop_requested"):
            progress_bar.empty()
            stop_button_placeholder.empty()
            realtime_info.empty()
            break
        
        time.sleep(check_interval)
        elapsed_time += check_interval
    
    if elapsed_time >= max_wait_time:
        progress_bar.empty()
        stop_button_placeholder.empty()
        realtime_info.empty()
        st.warning("â° ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: æœ€å¤§å¾…æ©Ÿæ™‚é–“ã‚’è¶…éã—ã¾ã—ãŸ")
    
    # åœæ­¢ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
    st.session_state.stop_requested = False


def _register_japanese_font():
    """æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ç™»éŒ²"""
    # UnicodeCIDFontã‚’ä½¿ç”¨ï¼ˆæ—¥æœ¬èªå¯¾å¿œã®çµ„ã¿è¾¼ã¿ãƒ•ã‚©ãƒ³ãƒˆï¼‰
    try:
        # HeiseiKakuGo-W5ï¼ˆå¹³æˆè§’ã‚´ã‚·ãƒƒã‚¯ï¼‰ã‚’è©¦ã™
        pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
        return 'HeiseiKakuGo-W5'
    except Exception as e1:
        try:
            # HeiseiMin-W3ï¼ˆå¹³æˆæ˜æœï¼‰ã‚’è©¦ã™
            pdfmetrics.registerFont(UnicodeCIDFont('HeiseiMin-W3'))
            return 'HeiseiMin-W3'
        except Exception as e2:
            # Windowsã®TTFãƒ•ã‚©ãƒ³ãƒˆã‚’è©¦ã™
            font_paths = [
                'C:/Windows/Fonts/msgothic.ttf',
                'C:/Windows/Fonts/meiryo.ttf',
                'C:/Windows/Fonts/msmincho.ttf',
            ]
            for font_path in font_paths:
                if os.path.exists(font_path):
                    try:
                        pdfmetrics.registerFont(TTFont('JapaneseFont', font_path))
                        return 'JapaneseFont'
                    except Exception:
                        continue
            
            # æœ€å¾Œã®æ‰‹æ®µã¨ã—ã¦ã€UnicodeCIDFontã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚’è©¦ã™
            try:
                pdfmetrics.registerFont(UnicodeCIDFont('HeiseiKakuGo-W5'))
                return 'HeiseiKakuGo-W5'
            except:
                # ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è­¦å‘Šã‚’å‡ºã—ã¦Helveticaã‚’ä½¿ç”¨
                import logging
                logging.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®ç™»éŒ²ã«å¤±æ•—ã—ã¾ã—ãŸã€‚æ—¥æœ¬èªãŒæ­£ã—ãè¡¨ç¤ºã•ã‚Œãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
                return 'Helvetica'


def _fetch_url_content(url: str) -> str:
    """URLå…ˆã®ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—ï¼ˆHTMLã®å ´åˆã¯trafilaturaã§è¨˜äº‹ã‚’æŠ½å‡ºï¼‰"""
    if not SCRAPING_AVAILABLE and not TRAFILATURA_AVAILABLE:
        return "ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆBeautifulSoupã¾ãŸã¯trafilaturaãŒå¿…è¦ã§ã™ï¼‰"
    
    # URLãŒPDFãƒ•ã‚¡ã‚¤ãƒ«ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    is_pdf = url.lower().endswith('.pdf') or '.pdf' in url.lower()
    
    try:
        # ã‚ˆã‚Šä¸€èˆ¬çš„ãªãƒ–ãƒ©ã‚¦ã‚¶ã®User-Agentã‚’ä½¿ç”¨ï¼ˆ403ã‚¨ãƒ©ãƒ¼ã‚’å›é¿ï¼‰
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8",
            "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
            "Accept-Encoding": "gzip, deflate, br",
            "Connection": "keep-alive",
            "Upgrade-Insecure-Requests": "1",
            "Sec-Fetch-Dest": "document",
            "Sec-Fetch-Mode": "navigate",
            "Sec-Fetch-Site": "none",
            "Cache-Control": "max-age=0"
        }
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯Acceptãƒ˜ãƒƒãƒ€ãƒ¼ã‚’å¤‰æ›´
        if is_pdf:
            headers["Accept"] = "application/pdf,application/octet-stream,*/*"
        
        response = requests.get(url, timeout=30, headers=headers, allow_redirects=True)
        response.raise_for_status()
        
        # Content-Typeã‚’ãƒã‚§ãƒƒã‚¯
        content_type = response.headers.get('Content-Type', '').lower()
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆ
        if is_pdf or 'application/pdf' in content_type:
            if PDF_TEXT_EXTRACTION_AVAILABLE:
                try:
                    # PyPDF2ã§PDFã‹ã‚‰ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
                    pdf_reader = PyPDF2.PdfReader(BytesIO(response.content))
                    text_content = ""
                    max_pages = min(len(pdf_reader.pages), 10)  # æœ€å¤§10ãƒšãƒ¼ã‚¸ã¾ã§
                    for i in range(max_pages):
                        page = pdf_reader.pages[i]
                        page_text = page.extract_text()
                        if page_text:
                            text_content += f"--- ãƒšãƒ¼ã‚¸ {i+1} ---\n\n{page_text}\n\n"
                    
                    if text_content.strip():
                        return text_content.strip()
                    else:
                        return f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸãŒã€ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸã€‚\nURL: {url}\n\nï¼ˆã“ã®PDFã¯ç”»åƒãƒ™ãƒ¼ã‚¹ã®PDFã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚OCRå‡¦ç†ãŒå¿…è¦ãªå ´åˆãŒã‚ã‚Šã¾ã™ï¼‰"
                except Exception as e:
                    return f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}\nURL: {url}"
            else:
                return f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—ã—ã¾ã—ãŸãŒã€ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«ã¯PyPDF2ãŒå¿…è¦ã§ã™ã€‚\nURL: {url}\n\nã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ–¹æ³•: pip install PyPDF2\n\nï¼ˆPDFãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’PDFã«å«ã‚ã‚‹ã«ã¯ã€PyPDF2ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ï¼‰"
        
        # HTMLãƒšãƒ¼ã‚¸ã®å ´åˆ - trafilaturaã‚’ä½¿ç”¨ã—ã¦è¨˜äº‹ã‚’æŠ½å‡º
        if TRAFILATURA_AVAILABLE:
            try:
                # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡º
                if response.encoding is None or response.encoding == 'ISO-8859-1':
                    response.encoding = response.apparent_encoding or 'utf-8'
                
                # trafilaturaã§è¨˜äº‹ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º
                extracted_text = trafilatura.extract(
                    response.text,
                    url=url,
                    include_comments=False,
                    include_tables=True,
                    include_images=False,
                    include_links=False,
                    output_format='plaintext'
                )
                
                if extracted_text and extracted_text.strip():
                    # ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
                    content = re.sub(r'\s+', ' ', extracted_text)
                    content = re.sub(r'\n\s*\n', '\n\n', content)
                    return content.strip()
            except Exception as e:
                # trafilaturaã§æŠ½å‡ºã«å¤±æ•—ã—ãŸå ´åˆã¯ã€BeautifulSoupã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
                import logging
                logging.warning(f"trafilaturaã§ã®æŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}ã€‚BeautifulSoupã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã—ã¾ã™ã€‚")
        
        # trafilaturaãŒåˆ©ç”¨ã§ããªã„å ´åˆã€ã¾ãŸã¯æŠ½å‡ºã«å¤±æ•—ã—ãŸå ´åˆã¯BeautifulSoupã‚’ä½¿ç”¨
        if SCRAPING_AVAILABLE:
            # æ–‡å­—ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’æ¤œå‡º
            if response.encoding is None or response.encoding == 'ISO-8859-1':
                response.encoding = response.apparent_encoding or 'utf-8'
            
            soup = BeautifulSoup(response.content, "html.parser", from_encoding=response.encoding)
            
            # ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã‚¹ã‚¿ã‚¤ãƒ«ã‚’é™¤å»
            for script in soup(["script", "style", "nav", "header", "footer", "aside"]):
                script.decompose()
            
            # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æŠ½å‡º
            main = soup.find("main")
            if main:
                content = main.get_text(separator="\n", strip=True)
            else:
                article = soup.find("article")
                if article:
                    content = article.get_text(separator="\n", strip=True)
                else:
                    body = soup.find("body")
                    if body:
                        content = body.get_text(separator="\n", strip=True)
                    else:
                        content = soup.get_text(separator="\n", strip=True)
            
            # ãƒ†ã‚­ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            content = re.sub(r'\s+', ' ', content)
            content = re.sub(r'\n\s*\n', '\n\n', content)
            
            if not content.strip():
                return f"ãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¾ã—ãŸãŒã€ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\nURL: {url}"
            
            return content.strip()
        else:
            return f"ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°æ©Ÿèƒ½ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ï¼ˆBeautifulSoupãŒå¿…è¦ã§ã™ï¼‰ã€‚\nURL: {url}"
        
    except requests.exceptions.HTTPError as e:
        if e.response.status_code == 403:
            return f"ãƒšãƒ¼ã‚¸ã¸ã®ã‚¢ã‚¯ã‚»ã‚¹ãŒæ‹’å¦ã•ã‚Œã¾ã—ãŸï¼ˆ403 Forbiddenï¼‰ã€‚\nURL: {url}\n\nã“ã®ãƒšãƒ¼ã‚¸ã¯ã‚¢ã‚¯ã‚»ã‚¹åˆ¶é™ã•ã‚Œã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã§ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€‚"
        elif e.response.status_code == 404:
            return f"ãƒšãƒ¼ã‚¸ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼ˆ404 Not Foundï¼‰ã€‚\nURL: {url}"
        else:
            return f"HTTPã‚¨ãƒ©ãƒ¼ ({e.response.status_code}): {str(e)}\nURL: {url}"
    except requests.exceptions.Timeout:
        return f"ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ30ç§’ï¼‰ã€‚\nURL: {url}"
    except requests.exceptions.RequestException as e:
        return f"ãƒšãƒ¼ã‚¸ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}\nURL: {url}"
    except Exception as e:
        return f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}\nURL: {url}"


def _download_pdf_file(url: str) -> Optional[bytes]:
    """PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/pdf,application/octet-stream,*/*",
        }
        response = requests.get(url, timeout=30, headers=headers, allow_redirects=True)
        response.raise_for_status()
        
        content_type = response.headers.get('Content-Type', '').lower()
        if 'application/pdf' in content_type or url.lower().endswith('.pdf'):
            return response.content
        return None
    except Exception as e:
        import logging
        logging.warning(f"PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã«å¤±æ•—: {url}, ã‚¨ãƒ©ãƒ¼: {e}")
        return None


def generate_sources_pdf(sources: List[Dict], selected_indices: List[int], theme: str = "å‚ç…§ã‚½ãƒ¼ã‚¹", progress_callback=None) -> BytesIO:
    """é¸æŠã•ã‚ŒãŸå‚ç…§ã‚½ãƒ¼ã‚¹ã®URLå…ˆãƒšãƒ¼ã‚¸ã‚’PDFå½¢å¼ã§ç”Ÿæˆï¼ˆPDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãã®ã¾ã¾åŸ‹ã‚è¾¼ã‚€ï¼‰"""
    if not PDF_AVAILABLE:
        raise ImportError("reportlabãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    # ã¾ãšã€PDFãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‚’æ¤œå‡º
    pdf_files = []
    html_sources = []
    
    for source_idx in selected_indices:
        if source_idx < 0 or source_idx >= len(sources):
            continue
        source = sources[source_idx]
        url = source.get('url', '')
        if url and (url.lower().endswith('.pdf') or '.pdf' in url.lower()):
            pdf_content = _download_pdf_file(url)
            if pdf_content:
                pdf_files.append((source_idx, pdf_content, source))
            else:
                html_sources.append((source_idx, source))
        else:
            html_sources.append((source_idx, source))
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œã‚‰ã‚’çµåˆ
    if pdf_files and len(pdf_files) == len(selected_indices) and PDF_TEXT_EXTRACTION_AVAILABLE:
        try:
            from PyPDF2 import PdfMerger
            pdf_merger = PdfMerger()
            
            for source_idx, pdf_content, source in pdf_files:
                pdf_merger.append(BytesIO(pdf_content))
            
            # çµåˆã•ã‚ŒãŸPDFã‚’è¿”ã™
            merged_buffer = BytesIO()
            pdf_merger.write(merged_buffer)
            pdf_merger.close()
            merged_buffer.seek(0)
            return merged_buffer
        except Exception as e:
            import logging
            logging.warning(f"PDFçµåˆã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ç”Ÿæˆã—ã¾ã™ã€‚")
    
    # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§PDFã‚’ç”Ÿæˆï¼ˆHTMLãƒšãƒ¼ã‚¸ã¾ãŸã¯PDFãƒ•ã‚¡ã‚¤ãƒ«ã¨HTMLãƒšãƒ¼ã‚¸ã®æ··åˆï¼‰
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ç™»éŒ²
    japanese_font = _register_japanese_font()
    
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    story = []
    styles = getSampleStyleSheet()
    
    # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼‰
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontName=japanese_font,
        fontSize=18,
        textColor=(0, 0, 0),
        spaceAfter=30,
        alignment=TA_LEFT
    )
    
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontName=japanese_font,
        fontSize=14,
        textColor=(0, 0, 0),
        spaceAfter=12,
        spaceBefore=12,
        alignment=TA_LEFT
    )
    
    normal_style = ParagraphStyle(
        'CustomNormal',
        parent=styles['Normal'],
        fontName=japanese_font,
        fontSize=10,
        textColor=(0, 0, 0),
        spaceAfter=6,
        alignment=TA_JUSTIFY,
        leading=14
    )
    
    url_style = ParagraphStyle(
        'CustomURL',
        parent=styles['Normal'],
        fontName=japanese_font,
        fontSize=9,
        textColor=(0, 0, 0.8),
        spaceAfter=6,
        alignment=TA_LEFT
    )
    
    content_style = ParagraphStyle(
        'CustomContent',
        parent=styles['Normal'],
        fontName=japanese_font,
        fontSize=9,
        textColor=(0, 0, 0),
        spaceAfter=6,
        alignment=TA_JUSTIFY,
        leading=12
    )
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    story.append(Paragraph(f"<b>{theme} - å‚ç…§ã‚½ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸å†…å®¹</b>", title_style))
    story.append(Spacer(1, 12))
    story.append(Paragraph(f"ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}", normal_style))
    story.append(Paragraph(f"é¸æŠã•ã‚ŒãŸã‚½ãƒ¼ã‚¹æ•°: {len(selected_indices)}ä»¶", normal_style))
    story.append(Spacer(1, 20))
    
    # é¸æŠã•ã‚ŒãŸã‚½ãƒ¼ã‚¹ã®URLå…ˆãƒšãƒ¼ã‚¸ã‚’å–å¾—ã—ã¦è¿½åŠ 
    total = len(selected_indices)
    pdf_files_to_merge = []  # çµåˆã™ã‚‹PDFãƒ•ã‚¡ã‚¤ãƒ«
    
    for idx, source_idx in enumerate(selected_indices, 1):
        if source_idx < 0 or source_idx >= len(sources):
            continue
        
        source = sources[source_idx]
        title = source.get('title', 'N/A')
        url = source.get('url', 'N/A')
        summary = source.get('summary', '')
        relevance_score = source.get('relevance_score')
        source_type = source.get('source', '')
        
        # é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
        if progress_callback:
            progress_callback(idx, total, title)
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
        is_pdf_url = url != 'N/A' and (url.lower().endswith('.pdf') or '.pdf' in url.lower())
        
        if is_pdf_url:
            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ã€ãã®ã¾ã¾ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦çµåˆç”¨ã«ä¿å­˜
            pdf_content = _download_pdf_file(url)
            if pdf_content:
                pdf_files_to_merge.append((source_idx, pdf_content, source))
                # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®æƒ…å ±ã‚’ãƒ†ã‚­ã‚¹ãƒˆPDFã«è¿½åŠ ï¼ˆçµåˆã§ããªã„å ´åˆã®ãŸã‚ï¼‰
                story.append(Paragraph(f"<b>{idx}. {title}</b>", heading_style))
                story.append(Paragraph(f"<b>URL:</b> {url}", url_style))
                if PDF_TEXT_EXTRACTION_AVAILABLE:
                    try:
                        from PyPDF2 import PdfReader
                        pdf_reader = PdfReader(BytesIO(pdf_content))
                        story.append(Paragraph(f"<b>PDFãƒ•ã‚¡ã‚¤ãƒ«:</b> {len(pdf_reader.pages)}ãƒšãƒ¼ã‚¸", normal_style))
                    except:
                        story.append(Paragraph("<b>PDFãƒ•ã‚¡ã‚¤ãƒ«:</b> å–å¾—æ¸ˆã¿", normal_style))
                story.append(Paragraph("ï¼ˆã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã¯çµåˆã•ã‚ŒãŸPDFã«å«ã¾ã‚Œã¾ã™ï¼‰", normal_style))
                story.append(Spacer(1, 12))
                continue
        
        # HTMLãƒšãƒ¼ã‚¸ã®å ´åˆ
        # ã‚½ãƒ¼ã‚¹ç•ªå·ã¨ã‚¿ã‚¤ãƒˆãƒ«
        story.append(Paragraph(f"<b>{idx}. {title}</b>", heading_style))
        
        # URL
        if url != 'N/A':
            story.append(Paragraph(f"<b>URL:</b> {url}", url_style))
            
            # URLå…ˆã®ãƒšãƒ¼ã‚¸ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’å–å¾—
            story.append(Spacer(1, 6))
            story.append(Paragraph("<b>ãƒšãƒ¼ã‚¸å†…å®¹:</b>", normal_style))
            
            page_content = _fetch_url_content(url)
            if page_content:
                # é•·ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é©åˆ‡ã«åˆ†å‰²ï¼ˆPDFã®åˆ¶é™ã‚’è€ƒæ…®ï¼‰
                # HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
                page_content_escaped = page_content.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
                # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ï¼ˆ10000æ–‡å­—ç¨‹åº¦ï¼‰
                if len(page_content_escaped) > 10000:
                    page_content_escaped = page_content_escaped[:10000] + "\n\n... (å†…å®¹ãŒé•·ã„ãŸã‚ä¸€éƒ¨ã‚’çœç•¥ã—ã¦ã„ã¾ã™)"
                
                # æ®µè½ã”ã¨ã«åˆ†å‰²ã—ã¦è¿½åŠ ï¼ˆé•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ã«å‡¦ç†ï¼‰
                paragraphs = page_content_escaped.split('\n\n')
                for para in paragraphs[:50]:  # æœ€å¤§50æ®µè½ã¾ã§
                    if para.strip():
                        story.append(Paragraph(para.strip(), content_style))
                        story.append(Spacer(1, 3))
            else:
                story.append(Paragraph("ãƒšãƒ¼ã‚¸å†…å®¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", content_style))
        
        # è¦ç´„ï¼ˆå…ƒã®è¦ç´„ã‚‚è¡¨ç¤ºï¼‰
        if summary:
            story.append(Spacer(1, 6))
            summary_escaped = summary.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            story.append(Paragraph(f"<b>è¦ç´„:</b> {summary_escaped}", normal_style))
        
        # é–¢é€£æ€§ã‚¹ã‚³ã‚¢
        if relevance_score is not None:
            story.append(Paragraph(f"<b>é–¢é€£æ€§ã‚¹ã‚³ã‚¢:</b> {relevance_score:.2f}", normal_style))
        
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
        if source_type:
            story.append(Paragraph(f"<b>ã‚½ãƒ¼ã‚¹:</b> {source_type}", normal_style))
        
        # ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šï¼ˆæœ€å¾Œã®é …ç›®ä»¥å¤–ï¼‰
        if idx < len(selected_indices):
            story.append(PageBreak())
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚‹å ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆPDFã®å¾Œã«çµåˆ
    if pdf_files_to_merge and PDF_TEXT_EXTRACTION_AVAILABLE:
        try:
            from PyPDF2 import PdfMerger
            # ã¾ãšãƒ†ã‚­ã‚¹ãƒˆPDFã‚’ç”Ÿæˆ
            doc.build(story)
            buffer.seek(0)
            
            # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµåˆ
            pdf_merger = PdfMerger()
            pdf_merger.append(buffer)  # ãƒ†ã‚­ã‚¹ãƒˆPDFã‚’è¿½åŠ 
            
            for source_idx, pdf_content, source in pdf_files_to_merge:
                pdf_merger.append(BytesIO(pdf_content))
            
            # çµåˆã•ã‚ŒãŸPDFã‚’è¿”ã™
            merged_buffer = BytesIO()
            pdf_merger.write(merged_buffer)
            pdf_merger.close()
            merged_buffer.seek(0)
            return merged_buffer
        except Exception as e:
            import logging
            logging.warning(f"PDFçµåˆã‚¨ãƒ©ãƒ¼: {e}ã€‚ãƒ†ã‚­ã‚¹ãƒˆPDFã®ã¿ã‚’è¿”ã—ã¾ã™ã€‚")
            buffer.seek(0)
            return buffer
        
        # è¦ç´„ï¼ˆå…ƒã®è¦ç´„ã‚‚è¡¨ç¤ºï¼‰
        if summary:
            story.append(Spacer(1, 6))
            summary_escaped = summary.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            story.append(Paragraph(f"<b>è¦ç´„:</b> {summary_escaped}", normal_style))
        
        # é–¢é€£æ€§ã‚¹ã‚³ã‚¢
        if relevance_score is not None:
            story.append(Paragraph(f"<b>é–¢é€£æ€§ã‚¹ã‚³ã‚¢:</b> {relevance_score:.2f}", normal_style))
        
        # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
        if source_type:
            story.append(Paragraph(f"<b>ã‚½ãƒ¼ã‚¹:</b> {source_type}", normal_style))
        
        # ãƒšãƒ¼ã‚¸åŒºåˆ‡ã‚Šï¼ˆæœ€å¾Œã®é …ç›®ä»¥å¤–ï¼‰
        if idx < len(selected_indices):
            story.append(PageBreak())
    
    # PDFã‚’ç”Ÿæˆ
    doc.build(story)
    buffer.seek(0)
    return buffer


def generate_single_source_pdf(source: Dict, source_idx: int, theme: str = "å‚ç…§ã‚½ãƒ¼ã‚¹") -> BytesIO:
    """å˜ä¸€ã®å‚ç…§ã‚½ãƒ¼ã‚¹ã®URLå…ˆãƒšãƒ¼ã‚¸ã‚’PDFå½¢å¼ã§ç”Ÿæˆï¼ˆPDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ãã®ã¾ã¾åŸ‹ã‚è¾¼ã‚€ï¼‰"""
    if not PDF_AVAILABLE:
        raise ImportError("reportlabãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã¾ã›ã‚“")
    
    title = source.get('title', 'N/A')
    url = source.get('url', 'N/A')
    summary = source.get('summary', '')
    relevance_score = source.get('relevance_score')
    source_type = source.get('source', '')
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®URLã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
    is_pdf_url = url != 'N/A' and (url.lower().endswith('.pdf') or '.pdf' in url.lower())
    
    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯ã€ãã®ã¾ã¾ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è¿”ã™
    if is_pdf_url and PDF_TEXT_EXTRACTION_AVAILABLE:
        pdf_content = _download_pdf_file(url)
        if pdf_content:
            return BytesIO(pdf_content)
    
    # HTMLãƒšãƒ¼ã‚¸ã¾ãŸã¯PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å–å¾—ã«å¤±æ•—ã—ãŸå ´åˆã€ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§PDFã‚’ç”Ÿæˆ
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ç™»éŒ²
    japanese_font = _register_japanese_font()
    
    buffer = BytesIO()
    doc = SimpleDocTemplate(buffer, pagesize=A4)
    story = []
    styles = getSampleStyleSheet()
    
    # ã‚«ã‚¹ã‚¿ãƒ ã‚¹ã‚¿ã‚¤ãƒ«ï¼ˆæ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã‚’ä½¿ç”¨ï¼‰
    title_style = ParagraphStyle(
        'CustomTitle',
        parent=styles['Heading1'],
        fontName=japanese_font,
        fontSize=18,
        textColor=(0, 0, 0),
        spaceAfter=30,
        alignment=TA_LEFT
    )
    
    heading_style = ParagraphStyle(
        'CustomHeading',
        parent=styles['Heading2'],
        fontName=japanese_font,
        fontSize=14,
        textColor=(0, 0, 0),
        spaceAfter=12,
        spaceBefore=12,
        alignment=TA_LEFT
    )
    
    normal_style = ParagraphStyle(
        'CustomNormal',
        parent=styles['Normal'],
        fontName=japanese_font,
        fontSize=10,
        textColor=(0, 0, 0),
        spaceAfter=6,
        alignment=TA_JUSTIFY,
        leading=14
    )
    
    url_style = ParagraphStyle(
        'CustomURL',
        parent=styles['Normal'],
        fontName=japanese_font,
        fontSize=9,
        textColor=(0, 0, 0.8),
        spaceAfter=6,
        alignment=TA_LEFT
    )
    
    content_style = ParagraphStyle(
        'CustomContent',
        parent=styles['Normal'],
        fontName=japanese_font,
        fontSize=9,
        textColor=(0, 0, 0),
        spaceAfter=6,
        alignment=TA_JUSTIFY,
        leading=12
    )
    
    # ã‚¿ã‚¤ãƒˆãƒ«
    story.append(Paragraph(f"<b>{theme} - å‚ç…§ã‚½ãƒ¼ã‚¹ãƒšãƒ¼ã‚¸å†…å®¹</b>", title_style))
    story.append(Spacer(1, 12))
    story.append(Paragraph(f"ä½œæˆæ—¥æ™‚: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}", normal_style))
    story.append(Spacer(1, 20))
    
    # ã‚½ãƒ¼ã‚¹æƒ…å ±
    story.append(Paragraph(f"<b>{title}</b>", heading_style))
    
    # URL
    if url != 'N/A':
        story.append(Paragraph(f"<b>URL:</b> {url}", url_style))
        
        # PDFãƒ•ã‚¡ã‚¤ãƒ«ã®å ´åˆã¯æƒ…å ±ã®ã¿è¡¨ç¤º
        if is_pdf_url:
            pdf_content = _download_pdf_file(url)
            if pdf_content and PDF_TEXT_EXTRACTION_AVAILABLE:
                try:
                    from PyPDF2 import PdfReader
                    pdf_reader = PdfReader(BytesIO(pdf_content))
                    story.append(Paragraph(f"<b>PDFãƒ•ã‚¡ã‚¤ãƒ«:</b> {len(pdf_reader.pages)}ãƒšãƒ¼ã‚¸", normal_style))
                except:
                    story.append(Paragraph("<b>PDFãƒ•ã‚¡ã‚¤ãƒ«:</b> å–å¾—æ¸ˆã¿", normal_style))
                story.append(Paragraph("ï¼ˆã“ã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã¯ãã®ã¾ã¾å«ã¾ã‚Œã¦ã„ã¾ã™ï¼‰", normal_style))
    
    # è¦ç´„ï¼ˆãƒšãƒ¼ã‚¸å†…å®¹ã®å‰ã«è¡¨ç¤ºï¼‰
    if summary:
        story.append(Spacer(1, 6))
        summary_escaped = summary.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
        story.append(Paragraph(f"<b>è¦ç´„:</b> {summary_escaped}", normal_style))
    
    # ãƒšãƒ¼ã‚¸å†…å®¹ï¼ˆè¦ç´„ã®å¾Œã«è¡¨ç¤ºï¼‰
    if url != 'N/A' and not is_pdf_url:
        story.append(Spacer(1, 6))
        story.append(Paragraph("<b>ãƒšãƒ¼ã‚¸å†…å®¹:</b>", normal_style))
        
        page_content = _fetch_url_content(url)
        if page_content:
            # é•·ã„ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’é©åˆ‡ã«åˆ†å‰²ï¼ˆPDFã®åˆ¶é™ã‚’è€ƒæ…®ï¼‰
            # HTMLã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†
            page_content_escaped = page_content.replace('&', '&amp;').replace('<', '&lt;').replace('>', '&gt;')
            # é•·ã™ãã‚‹å ´åˆã¯åˆ‡ã‚Šè©°ã‚ï¼ˆ10000æ–‡å­—ç¨‹åº¦ï¼‰
            if len(page_content_escaped) > 10000:
                page_content_escaped = page_content_escaped[:10000] + "\n\n... (å†…å®¹ãŒé•·ã„ãŸã‚ä¸€éƒ¨ã‚’çœç•¥ã—ã¦ã„ã¾ã™)"
            
            # æ®µè½ã”ã¨ã«åˆ†å‰²ã—ã¦è¿½åŠ ï¼ˆé•·ã„ãƒ†ã‚­ã‚¹ãƒˆã‚’é©åˆ‡ã«å‡¦ç†ï¼‰
            paragraphs = page_content_escaped.split('\n\n')
            for para in paragraphs[:50]:  # æœ€å¤§50æ®µè½ã¾ã§
                if para.strip():
                    story.append(Paragraph(para.strip(), content_style))
                    story.append(Spacer(1, 3))
        else:
            story.append(Paragraph("ãƒšãƒ¼ã‚¸å†…å®¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ", content_style))
    
    # é–¢é€£æ€§ã‚¹ã‚³ã‚¢
    if relevance_score is not None:
        story.append(Paragraph(f"<b>é–¢é€£æ€§ã‚¹ã‚³ã‚¢:</b> {relevance_score:.2f}", normal_style))
    
    # ã‚½ãƒ¼ã‚¹ã‚¿ã‚¤ãƒ—
    if source_type:
        story.append(Paragraph(f"<b>ã‚½ãƒ¼ã‚¹:</b> {source_type}", normal_style))
    
    # PDFã‚’ç”Ÿæˆ
    doc.build(story)
    buffer.seek(0)
    return buffer


def save_report_to_file(result: dict, research_id: str):
    """ãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    if not result.get("report") or not result["report"].get("draft"):
        return
    
    try:
        output_dir = project_root / "output"
        output_dir.mkdir(exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        theme = result.get("theme", "ãƒªã‚µãƒ¼ãƒ")
        safe_theme = "".join(c if c.isalnum() or c in (' ', '-', '_') else '_' for c in theme[:30])
        filename = f"report_{safe_theme}_{timestamp}.md"
        filepath = output_dir / filename
        
        # ãƒ¬ãƒãƒ¼ãƒˆã‚’Markdownå½¢å¼ã§æ§‹ç¯‰
        markdown_content = f"""# {theme}

## ãƒ¬ãƒãƒ¼ãƒˆæƒ…å ±

- **ä½œæˆæ—¥æ™‚**: {datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S")}
- **ãƒªã‚µãƒ¼ãƒID**: {research_id}
- **ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å›æ•°**: {result.get('statistics', {}).get('iterations', 0)}
- **åé›†ãƒ‡ãƒ¼ã‚¿æ•°**: {result.get('statistics', {}).get('sources_collected', 0)}

## èª¿æŸ»è¨ˆç”»

"""
        
        # èª¿æŸ»è¨ˆç”»ã‚’è¿½åŠ 
        if result.get("plan"):
            plan = result["plan"]
            markdown_content += f"**ãƒ†ãƒ¼ãƒ**: {plan.get('theme', theme)}\n\n"
            if plan.get("investigation_points"):
                markdown_content += "**èª¿æŸ»è¦³ç‚¹**:\n"
                for point in plan["investigation_points"]:
                    markdown_content += f"- {point}\n"
                markdown_content += "\n"
            if plan.get("search_queries"):
                markdown_content += "**æ¤œç´¢ã‚¯ã‚¨ãƒª**:\n"
                for query in plan["search_queries"]:
                    markdown_content += f"- {query}\n"
                markdown_content += "\n"
        
        # ãƒ¬ãƒãƒ¼ãƒˆæœ¬æ–‡ã‚’è¿½åŠ 
        markdown_content += "---\n\n"
        markdown_content += result["report"]["draft"]
        
        # å‚ç…§ã‚½ãƒ¼ã‚¹ã‚’è¿½åŠ ï¼ˆãƒ¬ãƒãƒ¼ãƒˆæœ¬æ–‡ã®æœ€å¾Œã«ç¢ºå®Ÿã«è¿½åŠ ï¼‰
        if result["report"].get("sources"):
            markdown_content += "\n\n---\n\n## ğŸ“š å‚ç…§ã‚½ãƒ¼ã‚¹\n\n"
            markdown_content += f"æœ¬ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆã«ã‚ãŸã‚Šã€ä»¥ä¸‹ã® {len(result['report']['sources'])} ä»¶ã®ã‚½ãƒ¼ã‚¹ã‚’å‚ç…§ã—ã¾ã—ãŸã€‚\n\n"
            
            for i, source in enumerate(result["report"]["sources"], 1):
                markdown_content += f"### {i}. {source.get('title', 'N/A')}\n\n"
                markdown_content += f"- **URL**: [{source.get('url', 'N/A')}]({source.get('url', 'N/A')})\n"
                if source.get("summary"):
                    # è¦ç´„ã¯å…¨æ–‡ã‚’è¡¨ç¤ºï¼ˆ200æ–‡å­—åˆ¶é™ã‚’å‰Šé™¤ï¼‰
                    markdown_content += f"- **è¦ç´„**: {source['summary']}\n"
                if source.get("relevance_score") is not None:
                    markdown_content += f"- **é–¢é€£æ€§ã‚¹ã‚³ã‚¢**: {source['relevance_score']:.2f}\n"
                if source.get("source"):
                    markdown_content += f"- **ã‚½ãƒ¼ã‚¹**: {source['source']}\n"
                markdown_content += "\n"
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(markdown_content)
        
        st.info(f"ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜ã—ã¾ã—ãŸ: `{filepath}`")
    except Exception as e:
        st.warning(f"ãƒ¬ãƒãƒ¼ãƒˆã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")


# ãƒ¡ã‚¤ãƒ³é–¢æ•°
def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    init_session_state()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    render_sidebar()
    
    # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãƒ¬ãƒ³ãƒ€ãƒªãƒ³ã‚°
    render_main_content()


if __name__ == "__main__":
    main()
